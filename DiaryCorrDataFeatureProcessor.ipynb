{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import itertools\n",
    "from itertools import product\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "import nolds\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "from PreprocessFcns import *\n",
    "import pywt\n",
    "import random\n",
    "from scipy.signal import butter, welch, filtfilt, resample\n",
    "from scipy.stats import skew, kurtosis, entropy, pearsonr\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn import multiclass\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set path to folder containing clinic watch data\n",
    "clinicpath = r'//FS2.smpp.local\\\\RTO\\\\CIS-PD Study\\MJFF Curation\\Finalized Dataset'\n",
    "# set path to folder containing home watch data\n",
    "homepath = r'//FS2.smpp.local\\\\RTO\\\\CIS-PD Study\\Patient Record Correlation'\n",
    "# set path to destination folder\n",
    "dest = r'//FS2.smpp.local\\\\RTO\\\\CIS-PD Study\\Watch Features Data'\n",
    "#---------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_diar = 'Table12.csv'\n",
    "dest_ext_diar = 'Diaries'\n",
    "file_name_diar = 'diar_timepoints.csv'\n",
    "\n",
    "timepoints_diar = pd.read_csv(os.path.join(homepath, dest_ext_diar, file_name_diar), parse_dates = [1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDiaryTimePath(timepoints_diar):\n",
    "    \n",
    "    # Initialize Empty Lists for Each Necessary Piece of Information from Each Record\n",
    "    StartTimestamps = []\n",
    "    EndTimestamps = []\n",
    "    SaveFilePaths = []\n",
    "    SubjID = []\n",
    "    \n",
    "    # Diaries\n",
    "    Subj = list(timepoints_diar.SubjID)\n",
    "    StartTimes = timepoints_diar.apply(lambda row: row.Timestamp + pd.Timedelta(unit = 'minute', value = -30), axis = 1)\n",
    "    EndTimes = timepoints_diar.apply(lambda row: row.Timestamp, axis = 1)\n",
    "    SavePaths = timepoints_diar.apply(lambda row: os.path.join(homepath, dest_ext_diar, str(row.SubjID), \n",
    "                                                                                        str(row.Timestamp)[:7], \n",
    "                                                                                        str(row.Timestamp)[8:10],\n",
    "                                                                                        str(row.Timestamp)[11:13] +\n",
    "                                                                                        str(row.Timestamp)[14:16] +\n",
    "                                                                                        str(row.Timestamp)[17:] + '.csv'), \n",
    "                                      axis = 1)\n",
    "    SubjID = SubjID + Subj\n",
    "    StartTimestamps = StartTimestamps + list(StartTimes)\n",
    "    EndTimestamps = EndTimestamps + list(EndTimes)\n",
    "    SaveFilePaths = SaveFilePaths + list(SavePaths)\n",
    "    \n",
    "    DiaryTimePath = pd.DataFrame(columns = ['SubjID', 'StartTimestamps', 'EndTimestamps', 'SaveFilePaths'])\n",
    "    \n",
    "    DiaryTimePath['SubjID'] = SubjID\n",
    "    DiaryTimePath['StartTimestamps'] = StartTimestamps\n",
    "    DiaryTimePath['EndTimestamps'] = EndTimestamps\n",
    "    DiaryTimePath['SaveFilePaths'] = SaveFilePaths\n",
    "    \n",
    "    return DiaryTimePath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "//FS2.smpp.local\\\\RTO\\\\CIS-PD Study\\Patient Record Correlation\\Diaries\\1046\\2017-10\\03\\170000.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SubjID</th>\n",
       "      <th>StartTimestamps</th>\n",
       "      <th>EndTimestamps</th>\n",
       "      <th>SaveFilePaths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1046</td>\n",
       "      <td>2017-09-18 12:30:00</td>\n",
       "      <td>2017-09-18 13:00:00</td>\n",
       "      <td>//FS2.smpp.local\\\\RTO\\\\CIS-PD Study\\Patient Re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1046</td>\n",
       "      <td>2017-09-18 13:00:00</td>\n",
       "      <td>2017-09-18 13:30:00</td>\n",
       "      <td>//FS2.smpp.local\\\\RTO\\\\CIS-PD Study\\Patient Re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1046</td>\n",
       "      <td>2017-09-18 13:30:00</td>\n",
       "      <td>2017-09-18 14:00:00</td>\n",
       "      <td>//FS2.smpp.local\\\\RTO\\\\CIS-PD Study\\Patient Re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1046</td>\n",
       "      <td>2017-09-18 14:00:00</td>\n",
       "      <td>2017-09-18 14:30:00</td>\n",
       "      <td>//FS2.smpp.local\\\\RTO\\\\CIS-PD Study\\Patient Re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1046</td>\n",
       "      <td>2017-09-18 14:30:00</td>\n",
       "      <td>2017-09-18 15:00:00</td>\n",
       "      <td>//FS2.smpp.local\\\\RTO\\\\CIS-PD Study\\Patient Re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SubjID     StartTimestamps       EndTimestamps  \\\n",
       "0    1046 2017-09-18 12:30:00 2017-09-18 13:00:00   \n",
       "1    1046 2017-09-18 13:00:00 2017-09-18 13:30:00   \n",
       "2    1046 2017-09-18 13:30:00 2017-09-18 14:00:00   \n",
       "3    1046 2017-09-18 14:00:00 2017-09-18 14:30:00   \n",
       "4    1046 2017-09-18 14:30:00 2017-09-18 15:00:00   \n",
       "\n",
       "                                       SaveFilePaths  \n",
       "0  //FS2.smpp.local\\\\RTO\\\\CIS-PD Study\\Patient Re...  \n",
       "1  //FS2.smpp.local\\\\RTO\\\\CIS-PD Study\\Patient Re...  \n",
       "2  //FS2.smpp.local\\\\RTO\\\\CIS-PD Study\\Patient Re...  \n",
       "3  //FS2.smpp.local\\\\RTO\\\\CIS-PD Study\\Patient Re...  \n",
       "4  //FS2.smpp.local\\\\RTO\\\\CIS-PD Study\\Patient Re...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DiaryTimePath = getDiaryTimePath(timepoints_diar)\n",
    "print(DiaryTimePath.SaveFilePaths[100])\n",
    "DiaryTimePath.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SubjID           Timestamp    Measurement Name  Value\n",
      "0    1046 2017-09-18 13:00:00              On/Off   -1.0\n",
      "1    1046 2017-09-18 13:30:00              Tremor    1.0\n",
      "2    1046 2017-09-18 13:30:00              On/Off    0.0\n",
      "3    1046 2017-09-18 13:30:00          Dyskinesia    0.0\n",
      "4    1046 2017-09-18 13:30:00  Activity Intensity    1.0\n"
     ]
    }
   ],
   "source": [
    "DiaryRecords = (pd.read_csv(os.path.join(clinicpath, 'Metadata Tables', 'Table12.csv'), parse_dates = ['Timestamp']) \n",
    "                [['SubjID', 'Timestamp', 'Measurement Name', 'Value']])\n",
    "print(DiaryRecords.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Path</th>\n",
       "      <th>SubjID</th>\n",
       "      <th>On/Off</th>\n",
       "      <th>Tremor</th>\n",
       "      <th>Dyskinesia</th>\n",
       "      <th>Activity Intensity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>//FS2.smpp.local\\\\RTO\\\\CIS-PD Study\\Patient Re...</td>\n",
       "      <td>1046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>//FS2.smpp.local\\\\RTO\\\\CIS-PD Study\\Patient Re...</td>\n",
       "      <td>1046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>//FS2.smpp.local\\\\RTO\\\\CIS-PD Study\\Patient Re...</td>\n",
       "      <td>1046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>//FS2.smpp.local\\\\RTO\\\\CIS-PD Study\\Patient Re...</td>\n",
       "      <td>1046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>//FS2.smpp.local\\\\RTO\\\\CIS-PD Study\\Patient Re...</td>\n",
       "      <td>1046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Path  SubjID  On/Off  Tremor  \\\n",
       "0  //FS2.smpp.local\\\\RTO\\\\CIS-PD Study\\Patient Re...    1046     0.0     0.0   \n",
       "1  //FS2.smpp.local\\\\RTO\\\\CIS-PD Study\\Patient Re...    1046     0.0     0.0   \n",
       "2  //FS2.smpp.local\\\\RTO\\\\CIS-PD Study\\Patient Re...    1046     0.0     0.0   \n",
       "3  //FS2.smpp.local\\\\RTO\\\\CIS-PD Study\\Patient Re...    1046     0.0     0.0   \n",
       "4  //FS2.smpp.local\\\\RTO\\\\CIS-PD Study\\Patient Re...    1046     0.0     0.0   \n",
       "\n",
       "   Dyskinesia  Activity Intensity  \n",
       "0         0.0                 2.0  \n",
       "1         0.0                 1.0  \n",
       "2         0.0                 1.0  \n",
       "3         0.0                 1.0  \n",
       "4         0.0                 1.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NoSympDiar = pd.DataFrame()\n",
    "for sub in DiaryRecords.SubjID.unique():\n",
    "    subDiaryRecords = DiaryRecords[DiaryRecords.SubjID == sub]\n",
    "    for time in subDiaryRecords.Timestamp.unique():\n",
    "        timesubDiaryRecords = subDiaryRecords[subDiaryRecords.Timestamp == time]\n",
    "        ind = ((timesubDiaryRecords['Measurement Name'] == 'Tremor') | \n",
    "               (timesubDiaryRecords['Measurement Name'] == 'On/Off') | \n",
    "               (timesubDiaryRecords['Measurement Name'] == 'Dyskinesia'))\n",
    "        if all(value == float(0) for value in timesubDiaryRecords.Value[ind]):\n",
    "            time = pd.Timestamp(time)\n",
    "            NoSymp = pd.DataFrame()\n",
    "            NoSymp['Path'] = [os.path.join(homepath, dest_ext_diar, \n",
    "                                           str(sub), str(time)[:7], str(time)[8:10],\n",
    "                                           str(time)[11:13] +\n",
    "                                           str(time)[14:16] +\n",
    "                                           str(time)[17:] + '.csv')]\n",
    "            NoSymp['SubjID'] = [sub]\n",
    "            NoSymp['On/Off'] = [np.max(timesubDiaryRecords.Value[timesubDiaryRecords['Measurement Name'] == \n",
    "                                                                 'On/Off'].values)]\n",
    "            NoSymp['Tremor'] = [np.max(timesubDiaryRecords.Value[timesubDiaryRecords['Measurement Name'] == \n",
    "                                                                 'Tremor'].values)]\n",
    "            NoSymp['Dyskinesia'] = [np.max(timesubDiaryRecords.Value[timesubDiaryRecords['Measurement Name'] == \n",
    "                                                                     'Dyskinesia'].values)]\n",
    "            NoSymp['Activity Intensity'] = [np.max(timesubDiaryRecords.Value[timesubDiaryRecords['Measurement Name'] == \n",
    "                                                                             'Activity Intensity'].values)]\n",
    "            if NoSympDiar.empty:\n",
    "                NoSympDiar = NoSymp\n",
    "                continue\n",
    "            NoSympDiar = pd.concat([NoSympDiar, NoSymp], ignore_index = True)\n",
    "NoSympDiar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'//FS2.smpp.local\\\\\\\\RTO\\\\\\\\CIS-PD Study\\\\Patient Record Correlation\\\\Diaries\\\\1046\\\\2017-09\\\\18\\\\203000.csv'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NoSympDiar.Path[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(data_clip):\n",
    "    \n",
    "    features_list = ['RMSX', 'RMSY', 'RMSZ', \n",
    "                     'rangeX', 'rangeY', 'rangeZ', \n",
    "                     'meanX', 'meanY', 'meanZ', \n",
    "                     'varX', 'varY', 'varZ', \n",
    "                     'skewX', 'skewY', 'skewZ', \n",
    "                     'kurtX', 'kurtY', 'kurtZ', \n",
    "                     'xcorr_peakXY', 'xcorr_peakXZ', 'xcorr_peakYZ', \n",
    "                     'xcorr_lagXY', 'xcorr_lagXZ', 'xcorr_lagYZ', \n",
    "                     'freq1', 'freq2', 'freq3', # added\n",
    "                     'P1_rel', 'P2_rel', 'P3_rel', # added\n",
    "                     'PSD_mean', 'PSD_std', 'PSD_skew', 'PSD_kur', \n",
    "                     'jerk_mean', 'jerk_std', 'jerk_skew', 'jerk_kur', \n",
    "                     'Sen_X', 'Sen_Y', 'Sen_Z', # not included in reduced features\n",
    "                     'RMS_mag', 'range_mag', 'mean_mag', 'var_mag', 'skew_mag', 'kurt_mag', 'Sen_mag'] # not included\n",
    "    \n",
    "    rawdata = data_clip\n",
    "    rawdata_wmag = rawdata.copy()\n",
    "    rawdata_wmag['Accel_Mag'] = np.sort((rawdata**2).sum(axis = 1))\n",
    "    \n",
    "    N = len(rawdata)\n",
    "    min_xyz = np.min(rawdata, axis = 0)\n",
    "    max_xyz = np.max(rawdata, axis = 0)\n",
    "    xcorr_xy = np.correlate(rawdata.iloc[:, 0], rawdata.iloc[:, 1], mode = 'same')\n",
    "    xcorr_xz = np.correlate(rawdata.iloc[:,0], rawdata.iloc[:, 2], mode = 'same')\n",
    "    xcorr_yz = np.correlate(rawdata.iloc[:, 1], rawdata.iloc[:, 2], mode = 'same')\n",
    "    Pxx = power_spectra_welch(rawdata_wmag, fm = 0, fM = 10)\n",
    "    sH_raw = []; sH_fft = []\n",
    "\n",
    "    \n",
    "    # RMSX, RMSY, RMSZ\n",
    "    # root mean square\n",
    "    RMS = 1 / N * np.sqrt(np.asarray(np.sum(rawdata**2, axis = 0)))\n",
    "    \n",
    "    # rangeX, rangeY, rangeZ\n",
    "    # range\n",
    "    r = np.asarray(max_xyz - min_xyz)\n",
    "    \n",
    "    # meanX, meanY, meanZ\n",
    "    # average\n",
    "    mean = np.asarray(np.mean(rawdata, axis = 0))\n",
    "\n",
    "    # varX, varY, varZ\n",
    "    # standard deviation\n",
    "    var = np.asarray(np.std(rawdata, axis = 0))\n",
    "\n",
    "    # skewX, skewY, skewZ\n",
    "    # skewness: measure of data symmetry\n",
    "    sk = skew(rawdata)\n",
    "    \n",
    "    # kurtX, kurtY, kurtZ\n",
    "    # kurtosis: measure of data tail weight compared to normal dist\n",
    "    kurt = kurtosis(rawdata)\n",
    "\n",
    "    # xcorr_peakXY, xcorr_peakXZ, xcorr_peakYZ\n",
    "    # max correlation between data of paired axes\n",
    "    xcorr_peak_xy = np.max(xcorr_xy)\n",
    "    xcorr_peak_xz = np.max(xcorr_xz)\n",
    "    xcorr_peak_yz = np.max(xcorr_yz)\n",
    "    xcorr_peak = np.array([xcorr_peak_xy, xcorr_peak_xz, xcorr_peak_yz])\n",
    "\n",
    "    # xcorr_lagXY, xcorr_lagXZ, xcorr_lagYZ\n",
    "    # relative location of max correlation between data of paired axes\n",
    "    xcorr_lag_xy = (np.argmax(xcorr_xy)) / len(xcorr_xy)\n",
    "    xcorr_lag_xz = (np.argmax(xcorr_xz)) / len(xcorr_xz)\n",
    "    xcorr_lag_yz = (np.argmax(xcorr_yz)) / len(xcorr_yz)\n",
    "    xcorr_lag = np.array([xcorr_lag_xy, xcorr_lag_xz, xcorr_lag_yz])\n",
    "\n",
    "    # freq1, freq2, freq3\n",
    "    # frequency with the highest power density\n",
    "    freq1 = Pxx.iloc[:, -1].index[-1]\n",
    "    freq2 = Pxx.iloc[:, -1].index[-2]\n",
    "    freq3 = Pxx.iloc[:, -1].index[-3]\n",
    "    domfreq = np.array([freq1, freq2, freq3])\n",
    "\n",
    "    # P1_rel, P2_rel, P3_rel\n",
    "    # relative power of the dominant frequency within the signal\n",
    "    P1_rel = Pxx.loc[freq1].values / Pxx.iloc[:, -1].sum()\n",
    "    P2_rel = Pxx.loc[freq2].values / Pxx.iloc[:, -1].sum()\n",
    "    P3_rel = Pxx.loc[freq3].values / Pxx.iloc[:, -1].sum()\n",
    "    Pdom_rel = np.concatenate((P1_rel, P2_rel, P3_rel))\n",
    "\n",
    "    # PDS_mean, PDS_std, PDS_skew, PDS_kur\n",
    "    # power spectral density summary stats\n",
    "    Pxx_moments = np.array([np.nanmean(Pxx.values), np.nanstd(Pxx.values), skew(Pxx.values), kurtosis(Pxx.values)])\n",
    "\n",
    "    # jerk_mean, jerk_std, jerk_skew, jerk_kur\n",
    "    jerk = rawdata_wmag['Accel_Mag'].diff().values\n",
    "    jerk_moments = np.array([np.nanmean(jerk), np.nanstd(jerk), skew(jerk[~np.isnan(jerk)]), kurtosis(jerk[~np.isnan(jerk)])])\n",
    "\n",
    "    # Sen_X, Sen_Y, Sen_Z\n",
    "    # sample entropy\n",
    "    for a in range(3):\n",
    "        x = rawdata.iloc[:, a]\n",
    "        n = len(x)\n",
    "        Fs = np.mean(1 / (np.diff(x.index) / 1000))\n",
    "        sH_raw.append(nolds.sampen(x))\n",
    "    \n",
    "    # features of the acceleration magnitude (as opposed to the axis values)\n",
    "    RMS_mag = 1 / N * np.sqrt(np.sum(rawdata_wmag['Accel_Mag']**2, axis = 0))\n",
    "    r_mag = np.max(rawdata_wmag['Accel_Mag']) - np.min(rawdata_wmag['Accel_Mag'])\n",
    "    mean_mag = np.mean(rawdata_wmag['Accel_Mag'])\n",
    "    var_mag = np.std(rawdata_wmag['Accel_Mag'])\n",
    "    sk_mag = skew(rawdata_wmag['Accel_Mag'])\n",
    "    kurt_mag = kurtosis(rawdata_wmag['Accel_Mag'])\n",
    "    sH_mag = nolds.sampen(rawdata_wmag['Accel_Mag'])\n",
    "    \n",
    "    Y = np.array([RMS_mag, r_mag, mean_mag, var_mag, sk_mag, kurt_mag, sH_mag])\n",
    "    X = np.concatenate((RMS, r, mean, var, sk, kurt, xcorr_peak, xcorr_lag, \n",
    "                        domfreq, Pdom_rel, Pxx_moments, jerk_moments, sH_raw, Y))\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataAggregator(file, data_type):\n",
    "    '''generates feature metrics for 5-second intervals of apple watch data\n",
    "       utilizes additional features not present in previous DataAggregator\n",
    "       data_type: \\'clinic\\' or \\'home\\'\n",
    "       file: clinic data in the form (SubjID)_(VisitNum)_(TaskAbb); home data as full record file path'''\n",
    "    \n",
    "    TaskFeatures = pd.DataFrame()\n",
    "    \n",
    "    if data_type == 'clinic':\n",
    "        subject = file[:4]\n",
    "        visit = file[5:6]\n",
    "        task = file[7:]\n",
    "    if data_type == 'home':\n",
    "        designation = file[63:-4]\n",
    "    print(file)\n",
    "    \n",
    "    features_list = ['RMSX', 'RMSY', 'RMSZ', \n",
    "                     'rangeX', 'rangeY', 'rangeZ', \n",
    "                     'meanX', 'meanY', 'meanZ', \n",
    "                     'varX', 'varY', 'varZ', \n",
    "                     'skewX', 'skewY', 'skewZ', \n",
    "                     'kurtX', 'kurtY', 'kurtZ', \n",
    "                     'xcorr_peakXY', 'xcorr_peakXZ', 'xcorr_peakYZ', \n",
    "                     'xcorr_lagXY', 'xcorr_lagXZ', 'xcorr_lagYZ', \n",
    "                     'freq1', 'freq2', 'freq3', # added\n",
    "                     'P1_rel', 'P2_rel', 'P3_rel', # added\n",
    "                     'PSD_mean', 'PSD_std', 'PSD_skew', 'PSD_kur', \n",
    "                     'jerk_mean', 'jerk_std', 'jerk_skew', 'jerk_kur', \n",
    "                     'Sen_X', 'Sen_Y', 'Sen_Z', # not included in reduced features\n",
    "                     'RMS_mag', 'range_mag', 'mean_mag', 'var_mag', 'skew_mag', 'kurt_mag', 'Sen_mag'] # not included\n",
    "        \n",
    "    # get acc data\n",
    "    try:\n",
    "        if data_type == 'clinic':\n",
    "            data = (pd.read_csv(os.path.join(clinicpath, 'Table8', 'TaskAcc', file + '.csv'), parse_dates = ['timestamp'])\n",
    "                    [['timestamp', 'x', 'y', 'z']])\n",
    "            data.columns = ['Timestamp', 'X', 'Y', 'Z']\n",
    "        if data_type == 'home':\n",
    "            data = pd.read_csv(file, parse_dates = ['Timestamp'])[['Timestamp', 'X', 'Y', 'Z']]\n",
    "    except(FileNotFoundError):\n",
    "        if data_type == 'clinic':\n",
    "            print('No data found for subject %s %s visit %s' % (subject, task, visit))\n",
    "        if data_type == 'home':\n",
    "            print('No data found for %s' % (designation))\n",
    "        return TaskFeatures\n",
    "        \n",
    "    # organize data and make 5 second clips\n",
    "    data = data.sort_values(by = 'Timestamp', axis = 0)\n",
    "    data['Timestamp2'] = [(tm - datetime.timedelta(minutes = 0,\n",
    "                                                   seconds = tm.second % 5,\n",
    "                                                   microseconds = tm.microsecond)) \n",
    "                          for tm in data.Timestamp]\n",
    "    \n",
    "    data['Timestamp'] = (data.Timestamp.values - data.Timestamp.values[0]).astype('timedelta64[ms]').astype(int)\n",
    "    data = data.set_index('Timestamp')\n",
    "    data.loc[:, ['X', 'Y', 'Z']] = filterdata(data[['X', 'Y', 'Z']])\n",
    "                \n",
    "    # \"clip\" the data into 5 second chunks    \n",
    "    five_sec_intervals = data.Timestamp2.unique()\n",
    "        \n",
    "    # calculate features\n",
    "    F = []\n",
    "    num_empty = 0\n",
    "    times = []\n",
    "    for t in five_sec_intervals:\n",
    "        clip = data.loc[(data.Timestamp2 == t)]\n",
    "        # length of 5 second chunk should be 250 for 5 seconds\n",
    "        if (clip.empty or (len(clip.Timestamp2) < 200)):\n",
    "            num_empty += 1\n",
    "        else:\n",
    "            F.append(feature_extraction(clip[['X', 'Y', 'Z']]))\n",
    "            times.append(t)\n",
    "            \n",
    "    # create features dataframe\n",
    "    TaskFeatures = pd.DataFrame(data = F, columns = features_list, dtype = 'float32')    \n",
    "    \n",
    "    return TaskFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "//FS2.smpp.local\\\\RTO\\\\CIS-PD Study\\Patient Record Correlation\\Diaries\\1046\\2017-09\\18\\140000.csv\n"
     ]
    }
   ],
   "source": [
    "### GENERATING FEATURES FROM HOME DATA RELATED TO DIARIES\n",
    "s_time = time.time()\n",
    "\n",
    "DataFeatures = pd.DataFrame()\n",
    "\n",
    "for diary in NoSympDiar.iterrows():\n",
    "    file = diary[1]['Path']\n",
    "    TaskFeatures = DataAggregator(file, 'home')\n",
    "    if TaskFeatures.empty:\n",
    "        continue\n",
    "    featcols = list(TaskFeatures.columns)\n",
    "    \n",
    "    TaskFeatures['SubjID'] = diary[1]['SubjID']\n",
    "    TaskFeatures['On/Off'] = diary[1]['On/Off']\n",
    "    TaskFeatures['Tremor'] = diary[1]['Tremor']\n",
    "    TaskFeatures['Dyskinesia'] = diary[1]['Dyskinesia']\n",
    "    TaskFeatures['Activity Intensity'] = diary[1]['Activity Intensity']\n",
    "    \n",
    "    cols = ['SubjID', 'On/Off', 'Tremor', 'Dyskinesia', 'Activity Intensity'] + featcols\n",
    "    TaskFeatures = TaskFeatures[cols]\n",
    "    \n",
    "    if DataFeatures.empty:\n",
    "        DataFeatures = TaskFeatures\n",
    "        continue\n",
    "    DataFeatures = pd.concat([DataFeatures, TaskFeatures], ignore_index = True)\n",
    "    \n",
    "DataFeatures.to_csv(os.path.join(dest, 'Home Data', 'DiaryDataFeatures_NoSymp.csv'), index = False)\n",
    "    \n",
    "print(str(int(((time.time() - s_time) / 60) / 60)) + ' hours ' + \n",
    "      str(int(((time.time() - s_time) / 60) % 60)) + ' minutes ' + \n",
    "      str(int((time.time() - s_time) % 60)) + ' seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['On/Off', 'Tremor', 'Dyskinesia', 'Activity Intensity'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DiaryRecords['Measurement Name'].unique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
