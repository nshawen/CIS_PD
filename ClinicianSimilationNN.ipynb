{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import bisect\n",
    "import datetime\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from PreprocessFcns import *\n",
    "import scipy\n",
    "from scipy.fftpack import fft\n",
    "from scipy.signal import butter, filtfilt, find_peaks\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'//FS2.smpp.local\\\\RTO\\\\CIS-PD Study\\MJFF Curation\\Finalized Dataset'\n",
    "dest = r'//FS2.smpp.local\\\\RTO\\\\CIS-PD Study\\Watch Features Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouper = LeaveOneGroupOut()\n",
    "sns.set(font_scale = 1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VisitNumber = {\n",
    "    '2 Weeks: Time 0'   : 0,\n",
    "    '2 Weeks: Time 30'  : 1,\n",
    "    '2 Weeks: Time 60'  : 2,\n",
    "    '2 Weeks: Time 90'  : 3,\n",
    "    '2 Weeks: Time 120' : 4,\n",
    "    '2 Weeks: Time 150' : 5,\n",
    "    '1 Month'           : 6\n",
    "}\n",
    "\n",
    "ClinicTasks = {\n",
    "    'Stndg'    : 'Standing',\n",
    "    'Wlkg'     : 'Walking',\n",
    "    'WlkgCnt'  : 'Walking while counting',\n",
    "    'FtnR'     : 'Finger to nose--right hand',\n",
    "    'FtnL'     : 'Finger to nose--left hand',\n",
    "    'RamR'     : 'Alternating right hand movements',\n",
    "    'RamL'     : 'Alternating left hand movements',\n",
    "    'SitStand' : 'Sit to stand',\n",
    "    'Drwg'     : 'Drawing on a paper',\n",
    "    'Typg'     : 'Typing on a computer keyboard',\n",
    "    'NtsBts'   : 'Assembling nuts and bolts',\n",
    "    'Drnkg'    : 'Taking a glass of water and drinking',\n",
    "    'Sheets'   : 'Organizing sheets in a folder',\n",
    "    'Fldg'     : 'Folding towels',\n",
    "    'Sitng'    : 'Sitting'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records = 2014\n"
     ]
    }
   ],
   "source": [
    "def filterMetaData():\n",
    "'''filter metadata file to remove empty data and unnecessary scores\n",
    "add necessary information including binary tremor scores\n",
    "\n",
    "tasks: list of tasks for which to retrieve metadata of'''\n",
    "\n",
    "    # open metadata containing scores for each symptom for each task completed\n",
    "    metaDataFull = pd.read_csv(os.path.join(path, 'Metadata Tables', 'Table4.csv'))\n",
    "#     # isolate metadata corresponding to tasks of interest specified\n",
    "#     indices = (x for x in range(len(metaDataFull)) if metaDataFull.TaskAbb.values[x] in tasks)\n",
    "#     metaDataFull = metaDataFull.loc[indices]\n",
    "\n",
    "    SubjID = []\n",
    "    Visit = []\n",
    "    TaskAbb = []\n",
    "    AccFile = []\n",
    "    Tremor = []\n",
    "    for record in metaDataFull.iterrows():\n",
    "        # eliminate rows of metadata that contain nan values\n",
    "        if (type(record[1]['Side']) == float):\n",
    "            continue\n",
    "        if (np.isnan(record[1]['Tremor - ' + record[1]['Side']])):\n",
    "            continue\n",
    "        # build file name of the recording related to each piece of metadata\n",
    "        filename = (str(int(record[1]['SubjID'])) + '_' +\n",
    "                            str(VisitNumber[record[1]['Visit']]) + '_' + \n",
    "                            record[1]['TaskAbb'] + '.csv')\n",
    "        # add file name to file path for easy access\n",
    "        filepath = os.path.join(path, 'TaskAcc', filename)\n",
    "        # test is the recording file exists (not all metadata has related acceleration recording)\n",
    "        if not os.path.exists(filepath):\n",
    "            continue\n",
    "        SubjID = SubjID + [int(record[1]['SubjID'])]\n",
    "        Visit = Visit + [VisitNumber[record[1]['Visit']]]\n",
    "        TaskAbb = TaskAbb + [record[1]['TaskAbb']]\n",
    "        AccFile = AccFile + [filename]\n",
    "        # only concerned with tremor score on the side of subject wearing the apple watch\n",
    "        Tremor = Tremor + [int(record[1]['Tremor - ' + record[1]['Side']])]\n",
    "    # create column with binary tremor scores (symptomatic vs normal)\n",
    "    TremorBIN = [int(t > 0) for t in Tremor]\n",
    "    metaData = pd.DataFrame({'SubjID': SubjID, \n",
    "                             'Visit': Visit, \n",
    "                             'TaskAbb': TaskAbb,\n",
    "                             'AccFile': AccFile,\n",
    "                             'Tremor': Tremor,\n",
    "                             'TremorBIN': TremorBIN})\n",
    "    print('Records = ' + str(len(metaData)))\n",
    "    \n",
    "    return metaData\n",
    "\n",
    "metaData = filterMetaData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DetectDiscernAnomalyNN(tasks, segment, binary, anomaly, metaData):\n",
    "    '''follows two-step architecture to first detect anomaly in data and filter accordingly\n",
    "    predictions made on clips that are extrapolated to the scale of the recordings for validaiton\n",
    "    \n",
    "    tasks: list of tasks to be considered (Sitting or Standing ideally)\n",
    "    binary: True/False - whether or not all scores should be considered or just looking for presence of symptom\n",
    "    anomaly: whether or not to detect and filter by anomaly\n",
    "    metaData: variable containing relevant metadata generated from the function above'''\n",
    "    \n",
    "    # isolate only metadata corresponding to tasks of interest\n",
    "    indices = (x for x in range(len(metaData)) if metaData.TaskAbb.values[x] in tasks)\n",
    "    metaData = metaData.loc[indices]\n",
    "    \n",
    "    if binary:\n",
    "        # consider only binay scores (symptomatic - 1 or normal - 0)\n",
    "        tremScore = 'TremorBIN'\n",
    "    else:\n",
    "        # consider all scores on the UPDRS\n",
    "        tremScore = 'Tremor'\n",
    "    \n",
    "    # set threshold for RMSE of acceleration magnitude at which to consider an anomaly\n",
    "    NormRMSE = 0.01\n",
    "    \n",
    "    Data = []\n",
    "    Anomalies = []\n",
    "    Labels = []\n",
    "    Subjects = []\n",
    "    Recordings = []\n",
    "    \n",
    "    for record in metaData.iterrows():\n",
    "        # get the acceleration from the recording corresponding to each item of metadata in the filtered metadata\n",
    "        recording = pd.read_csv(os.path.join(path, 'TaskAcc', record[1]['AccFile']), \n",
    "                                parse_dates = ['timestamp'])[['timestamp', 'x', 'y', 'z']]\n",
    "        recording.columns = ['Timestamp', 'X', 'Y', 'Z']\n",
    "        # calculate magnitude of metadata without filtering the raw data\n",
    "        recording['Mag'] = np.sqrt((recording.X**2 + recording.Y**2 + recording.Z**2))\n",
    "        recording = recording.sort_values(by = 'Timestamp', axis = 0)\n",
    "        \n",
    "        if segment:\n",
    "            # group data points in the recording according to intervals\n",
    "            # change interval by changing the modulo number to half of window length\n",
    "            recording['TimeWdw'] = [(tm - datetime.timedelta(minutes = 0,\n",
    "                                                             seconds = tm.second % 2.5,\n",
    "                                                             microseconds = tm.microsecond)) \n",
    "                                    for tm in recording.Timestamp]\n",
    "            # organize the data by index of epoch time value from first data point in recording\n",
    "            recording['TimeIdx'] = (recording.Timestamp.values - \n",
    "                                    recording.Timestamp.values[0]).astype('timedelta64[ms]').astype(int)\n",
    "            recording = recording.set_index('TimeIdx')\n",
    "            for t in recording.TimeWdw.unique():\n",
    "                # segment the recording into clips grouped by interval with 50% overlap\n",
    "                # change length of window by changing the value in the timedelta to half of desired\n",
    "                clip = recording.loc[(recording.TimeWdw == t) | \n",
    "                                     (recording.TimeWdw == (t + np.timedelta64(2500, 'ms')))]\n",
    "                # discard clips significantly different in length from desired time length (50Hz - 5 sec is 250)\n",
    "                if len(clip) < 200:\n",
    "                    continue\n",
    "                    \n",
    "                if anomaly:\n",
    "                    # begin generation of an array classifying each segment as anomalous or not for future filtering\n",
    "                    if np.sqrt(np.mean((clip.Mag - np.mean(clip.Mag))**2)) < NormRMSE:\n",
    "                        Anomalies = Anomalies + [0]\n",
    "                    else:\n",
    "                        Anomalies = Anomalies + [1]\n",
    "                        \n",
    "                # upsample the three axes of each clip to normalize length and increase resolution\n",
    "                fx = scipy.interpolate.interp1d(range(len(clip)), clip.X.values)\n",
    "                fy = scipy.interpolate.interp1d(range(len(clip)), clip.Y.values)\n",
    "                fz = scipy.interpolate.interp1d(range(len(clip)), clip.Z.values)\n",
    "                clipX = fx(np.linspace(start = 0, stop = len(clip) - 1, num = 500))\n",
    "                clipY = fy(np.linspace(start = 0, stop = len(clip) - 1, num = 500))\n",
    "                clipZ = fz(np.linspace(start = 0, stop = len(clip) - 1, num = 500))\n",
    "                # reshape upsampled data into a rectangular form that can be inputted into the neural network\n",
    "                datasteps = []\n",
    "                for dpx, dpy, dpz in zip(clipX, clipY, clipZ):\n",
    "                    datasteps = datasteps + [[dpx, dpy, dpz]]\n",
    "                Data = Data + [datasteps]\n",
    "                # add relevant metadata to correlate to the acceleration data being formatted\n",
    "                Labels = Labels + [record[1][tremScore]]\n",
    "                Subjects = Subjects + [record[1]['SubjID']]\n",
    "                Recordings = Recordings + [str(int(record[1]['SubjID'])) + '_' + \n",
    "                                           str(int(record[1]['Visit'])) + '_' +\n",
    "                                           record[1]['TaskAbb']]\n",
    "        \n",
    "        # if recordings are to be considered as a whole by the neural network as opposed to clips\n",
    "        else:\n",
    "            if anomaly:\n",
    "                # classify whole recording as anomaly according to threshold of RMSE\n",
    "                if np.sqrt(np.mean((recording.Mag - np.mean(recording.Mag))**2)) < NormRMSE:\n",
    "                    Anomalies = Anomalies + [0]\n",
    "                else:\n",
    "                    Anomalies = Anomalies + [1]\n",
    "                    \n",
    "            # upsample full recordings to 1000 points for normalization and formatting\n",
    "            fx = scipy.interpolate.interp1d(range(len(recording)), recording.X.values)\n",
    "            fy = scipy.interpolate.interp1d(range(len(recording)), recording.Y.values)\n",
    "            fz = scipy.interpolate.interp1d(range(len(recording)), recording.Z.values)\n",
    "            clipX = fx(np.linspace(start = 0, stop = len(recording) - 1, num = 1000))\n",
    "            clipY = fy(np.linspace(start = 0, stop = len(recording) - 1, num = 1000))\n",
    "            clipZ = fz(np.linspace(start = 0, stop = len(recording) - 1, num = 1000))\n",
    "            # reshape upsampled data into a rectangular form that can be inputted into the neural network\n",
    "            datasteps = []\n",
    "            for dpx, dpy, dpz in zip(clipX, clipY, clipZ):\n",
    "                datasteps = datasteps + [[dpx, dpy, dpz]]\n",
    "            Data = Data + [datasteps]\n",
    "            # add relevant metadata to correltate to teh acceleration data being formatted\n",
    "            Labels = Labels + [record[1][tremScore]]\n",
    "            Subjects = Subjects + [record[1]['SubjID']]\n",
    "            Recordings = Recordings + [str(int(record[1]['SubjID'])) + '_' + \n",
    "                                       str(int(record[1]['Visit'])) + '_' +\n",
    "                                       record[1]['TaskAbb']]\n",
    "\n",
    "    # convert all generated data and metadata to arrays to be used by the neural network\n",
    "    Data = np.array(Data)\n",
    "    Anomalies = np.array(Anomalies)\n",
    "    Labels = np.array(Labels)\n",
    "    subjects = np.array(Subjects)\n",
    "    recordings = np.array(Recordings)\n",
    "\n",
    "    print('(Samples, Timesteps, Features (Axes)) = ' + str(Data.shape))\n",
    "    print('Labels = ' + str(len(Labels)))\n",
    "    \n",
    "    if anomaly:\n",
    "        # filter all data to separate anomalous data for fitting model and other data for bypassing model and prediction\n",
    "        Recordings = recordings[Anomalies == 0]\n",
    "        Subjects = subjects[Anomalies == 0]\n",
    "        Scores = Labels[Anomalies == 0]\n",
    "        Predictions = [0] * len(Recordings)\n",
    "        Densities = [0] * len(Recordings)\n",
    "        \n",
    "        Data = Data[Anomalies == 1]\n",
    "        Labels = Labels[Anomalies == 1]\n",
    "        subjects = subjects[Anomalies == 1]\n",
    "        recordings = recordings[Anomalies == 1]\n",
    "        \n",
    "    else:\n",
    "        Recordings = []\n",
    "        Subjects = []\n",
    "        Scores = []\n",
    "        Predictions = []\n",
    "        Densities = []\n",
    "\n",
    "    TestLabs = []\n",
    "    PredLabs = []\n",
    "    testInds = []\n",
    "    # split dataset by subject to validation on each subject's data separately (leave-one-subject-out method)\n",
    "    for trainInd, testInd in grouper.split(Data, Labels, groups = subjects):\n",
    "\n",
    "        TrainData = Data[trainInd]\n",
    "        TrainLab = Labels[trainInd]\n",
    "        TestData = Data[testInd]\n",
    "\n",
    "        TestLab = Labels[testInd]\n",
    "\n",
    "        # initialize sequential neural network\n",
    "        model = Sequential()\n",
    "        # add a long short term memory layer specifying the input shape (length of 500 (segmented) with 3 axes)\n",
    "        model.add(LSTM(50, input_shape = (500, 3)))\n",
    "        # add a dense layer with a sigmoid activation function\n",
    "        model.add(Dense(1, activation = 'sigmoid'))\n",
    "        # compile the neural network with a mae loss function and adam optimizer\n",
    "        model.compile(loss = 'mae', optimizer = 'adam')\n",
    "        history = model.fit(TrainData, TrainLab, epochs = 10, batch_size = int(len(trainInd) / 20), \n",
    "                            validation_data = (TestData, TestLab))\n",
    "        # fit the model using the training set and validate on the subject data left out\n",
    "        PredLab = model.predict(TestData, verbose = 0)\n",
    "\n",
    "        # organlize testing and predicting labels into a dataframe that mirrors the order of original data arrays\n",
    "        TestLabs = TestLabs + list(TestLab)\n",
    "        PredLabs = PredLabs + list(PredLab)\n",
    "        testInds = testInds + list(testInd)\n",
    "            \n",
    "    TestPred = pd.DataFrame(index = testInds)\n",
    "    TestPred['TestLabs'] = TestLabs\n",
    "    TestPred['PredLabs'] = PredLabs\n",
    "\n",
    "    if segment:\n",
    "        # iterate through each recording with clips that the neural network predicted on\n",
    "        for rec in set(recordings):\n",
    "            # get the score/label for the recording\n",
    "            recLab = int(Labels[pd.Series(recordings) == rec][0])\n",
    "            # get the subject corresponding to the recording\n",
    "            recsub = int(subjects[pd.Series(recordings) == rec][0])\n",
    "            # isolate the clip true and predicted labels that corresponding to the recording\n",
    "            recTestPred = TestPred[pd.Series(recordings) == rec]\n",
    "            \n",
    "            if binary:\n",
    "                if any(TestPred.PredLabs == 1):\n",
    "\n",
    "                    if TestPred.PredLabs.value_counts()[1] > 1:\n",
    "\n",
    "                        Recordings = Recordings + [rec]\n",
    "                        Subjects = Subjects + [recsub]\n",
    "                        Scores = Scores + [recLab]\n",
    "                        Predictions = Predictions + [1]\n",
    "                        # density is the relative amount of symptomatic clips in the recording\n",
    "                        Densities = Densities + [TestPred.PredLabs.value_counts()[1] / \n",
    "                                             len(TestPred.PredLabs)]\n",
    "                    # if not enough of the clips of the recording are scored as symptomatic - recording is normal\n",
    "                    else:\n",
    "                        Recordings = Recordings + [rec]\n",
    "                        Subjects = Subjects + [recsub]\n",
    "                        Scores = Scores + [recLab]\n",
    "                        Predictions = Predictions + [0]\n",
    "                        # density is the relative amount of symptomatic clips in the recording\n",
    "                        Densities = Densities + [0]\n",
    "                # if none of the clips are predicted symptomatic - recording is normal (0)\n",
    "                else:\n",
    "                    Recordings = Recordings + [rec]\n",
    "                    Subjects = Subjects + [recsub]\n",
    "                    Scores = Scores + [recsub]\n",
    "                    Predictions = Predictions + [0]\n",
    "                    # density is the relative amount of symptomatic clips in the recording\n",
    "                    Densities = Densities + [0]\n",
    "            # classify recording based on the maximum score given to a clip from it\n",
    "            else:\n",
    "                Recordings = Recordings + [rec]\n",
    "                Subjects = Subjects + [recsub]\n",
    "                Scores = Scores + [recSub]\n",
    "                Predictions = Predictions + [np.max(TestPred.PredLabs)]\n",
    "                # density is the relative amount of symptomatic clips in the recording\n",
    "                # if statement avoids error if no zero scores are present\n",
    "                if any(TSVTestPred.PredLabs == 0):\n",
    "                    Densities = Densities + [1 - (TestPred.PredLabs.value_counts()[0] / len(TestPred.PredLabs))]\n",
    "                else:\n",
    "                    Densities = Densities + [1]\n",
    "                        \n",
    "    # consolidate predictions on recording scale with other metadata into a dataframe\n",
    "    RecordingAnalysis = pd.DataFrame({'Subject': Subjects, \n",
    "                                      'Score': Scores, 'Prediction': Predictions, 'Density': Densities}, \n",
    "                                     index = Recordings)\n",
    "    \n",
    "    # print the overall accuracy of the full scope of this model in predicting recording scores\n",
    "    print('Model Accuracy = ' + str((len(RecordingAnalysis[RecordingAnalysis.Score == RecordingAnalysis.Prediction])\n",
    "                                     / len(RecordingAnalysis)) * 100))\n",
    "    \n",
    "    # format predictions for use in a confusion matrix that will be outputted\n",
    "    CM = sklearn.metrics.confusion_matrix(RecordingAnalysis.Score.values, RecordingAnalysis.Prediction.values, \n",
    "                                          labels = le.classes_)\n",
    "    \n",
    "    # normalize confusion matrix rows to percents\n",
    "    for i in range(len(CM)):\n",
    "        CM[i, :] = (CM[i, :] / sum(CM[i, :])) * 100\n",
    "        \n",
    "    if binary:\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------------------------------\n",
    "        \n",
    "        # plot ROC curve for each subject whose data was used to validate the fit model for analysis\n",
    "        plt.figure(figsize = (12, 10))\n",
    "        for subject in RecordingAnalysis.Subject.unique():\n",
    "            SRecordingAnalysis = RecordingAnalysis[RecordingAnalysis.Subject == subject]\n",
    "            if (len(SRecordingAnalysis) == 1):\n",
    "                continue\n",
    "            # true labels: scored binary labels of each recording\n",
    "            TL = SRecordingAnalysis.Score.values\n",
    "            if all(TL == 0):\n",
    "                continue\n",
    "            # predicted labels: density of symptomatic clips in symptomatic recording\n",
    "            PL = SRecordingAnalysis.Density.values\n",
    "            # generate ROC curve\n",
    "            fpr, tpr, thresholds = sklearn.metrics.roc_curve(TL, PL)\n",
    "            plt.plot(fpr, tpr)\n",
    "            plt.xlabel('False Positive Rate', fontsize = 20)\n",
    "            plt.ylabel('True Positive Rate', fontsize = 20)\n",
    "        # generate legend of subjects that correspond to curves\n",
    "        plt.legend(RecordingAnalysis.Subject.unique())\n",
    "        plt.show()\n",
    "            \n",
    "# -------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "        plt.figure(figsize = (6, 5))\n",
    "    else:\n",
    "        plt.figure(figsize = (12, 10))\n",
    "    # plot confusion matrix to analyze true and predicted labels of recordings\n",
    "    sns.heatmap(CM, vmin = 0, vmax = 100, annot = True)\n",
    "    plt.xticks(fontsize = 14)\n",
    "    if binary:\n",
    "        plt.yticks(fontsize = 14)\n",
    "    else:\n",
    "        plt.yticks(fontsize = 14, rotation = 0)\n",
    "    plt.xlabel('Predicted', fontsize = 16)\n",
    "    plt.ylabel('Test', fontsize = 16)\n",
    "    \n",
    "    return RecordingAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Samples, Timesteps, Features (Axes)) = (3053, 500, 3)\n",
      "Labels = 3053\n",
      "Train on 968 samples, validate on 81 samples\n",
      "Epoch 1/10\n",
      "968/968 [==============================] - 14s 14ms/step - loss: 0.4863 - val_loss: 0.4831\n",
      "Epoch 2/10\n",
      "968/968 [==============================] - 15s 16ms/step - loss: 0.4432 - val_loss: 0.4723\n",
      "Epoch 3/10\n",
      "968/968 [==============================] - 12s 12ms/step - loss: 0.3723 - val_loss: 0.5345\n",
      "Epoch 4/10\n",
      "968/968 [==============================] - 12s 12ms/step - loss: 0.3338 - val_loss: 0.5821\n",
      "Epoch 5/10\n",
      "968/968 [==============================] - 12s 12ms/step - loss: 0.3584 - val_loss: 0.6008\n",
      "Epoch 6/10\n",
      "968/968 [==============================] - 12s 12ms/step - loss: 0.3555 - val_loss: 0.6024\n",
      "Epoch 7/10\n",
      "968/968 [==============================] - 12s 12ms/step - loss: 0.3499 - val_loss: 0.5900\n",
      "Epoch 8/10\n",
      "968/968 [==============================] - 12s 12ms/step - loss: 0.3362 - val_loss: 0.6037\n",
      "Epoch 9/10\n",
      "968/968 [==============================] - 12s 12ms/step - loss: 0.3573 - val_loss: 0.6044\n",
      "Epoch 10/10\n",
      "968/968 [==============================] - 12s 12ms/step - loss: 0.3519 - val_loss: 0.6045\n",
      "Train on 1016 samples, validate on 33 samples\n",
      "Epoch 1/10\n",
      "1016/1016 [==============================] - 12s 12ms/step - loss: 0.4920 - val_loss: 0.5116\n",
      "Epoch 2/10\n",
      "1016/1016 [==============================] - 12s 12ms/step - loss: 0.4443 - val_loss: 0.4483\n",
      "Epoch 3/10\n",
      "1016/1016 [==============================] - 12s 12ms/step - loss: 0.3907 - val_loss: 0.5040\n",
      "Epoch 4/10\n",
      "1016/1016 [==============================] - 12s 11ms/step - loss: 0.3650 - val_loss: 0.6455\n",
      "Epoch 5/10\n",
      "1016/1016 [==============================] - 12s 11ms/step - loss: 0.3691 - val_loss: 0.6601\n",
      "Epoch 6/10\n",
      "1016/1016 [==============================] - 11s 11ms/step - loss: 0.3664 - val_loss: 0.6630\n",
      "Epoch 7/10\n",
      "1016/1016 [==============================] - 11s 11ms/step - loss: 0.3667 - val_loss: 0.6641\n",
      "Epoch 8/10\n",
      "1016/1016 [==============================] - 12s 11ms/step - loss: 0.3663 - val_loss: 0.6648\n",
      "Epoch 9/10\n",
      "1016/1016 [==============================] - 12s 11ms/step - loss: 0.3660 - val_loss: 0.6652\n",
      "Epoch 10/10\n",
      "1016/1016 [==============================] - 11s 11ms/step - loss: 0.3658 - val_loss: 0.6657\n",
      "Train on 1042 samples, validate on 7 samples\n",
      "Epoch 1/10\n",
      "1042/1042 [==============================] - 12s 12ms/step - loss: 0.4869 - val_loss: 0.3216\n",
      "Epoch 2/10\n",
      "1042/1042 [==============================] - 11s 11ms/step - loss: 0.4422 - val_loss: 0.2695\n",
      "Epoch 3/10\n",
      "1042/1042 [==============================] - 11s 11ms/step - loss: 0.3824 - val_loss: 0.0073\n",
      "Epoch 4/10\n",
      "1042/1042 [==============================] - 11s 11ms/step - loss: 0.3514 - val_loss: 0.0042\n",
      "Epoch 5/10\n",
      "1042/1042 [==============================] - 11s 11ms/step - loss: 0.3323 - val_loss: 0.0031\n",
      "Epoch 6/10\n",
      "1042/1042 [==============================] - 11s 11ms/step - loss: 0.3656 - val_loss: 0.0028\n",
      "Epoch 7/10\n",
      "1042/1042 [==============================] - 12s 11ms/step - loss: 0.3310 - val_loss: 0.0025\n",
      "Epoch 8/10\n",
      "1042/1042 [==============================] - 11s 11ms/step - loss: 0.3369 - val_loss: 0.0025\n",
      "Epoch 9/10\n",
      "1042/1042 [==============================] - 12s 11ms/step - loss: 0.3628 - val_loss: 0.0024\n",
      "Epoch 10/10\n",
      "1042/1042 [==============================] - 12s 11ms/step - loss: 0.3745 - val_loss: 0.0023\n",
      "Train on 1044 samples, validate on 5 samples\n",
      "Epoch 1/10\n",
      "1044/1044 [==============================] - 12s 12ms/step - loss: 0.4859 - val_loss: 0.6231\n",
      "Epoch 2/10\n",
      "1044/1044 [==============================] - 12s 11ms/step - loss: 0.4374 - val_loss: 0.7042\n",
      "Epoch 3/10\n",
      "1044/1044 [==============================] - 12s 11ms/step - loss: 0.4232 - val_loss: 0.7554\n",
      "Epoch 4/10\n",
      "1044/1044 [==============================] - 12s 11ms/step - loss: 0.4195 - val_loss: 0.8343\n",
      "Epoch 5/10\n",
      "1044/1044 [==============================] - 11s 11ms/step - loss: 0.3995 - val_loss: 0.8888\n",
      "Epoch 6/10\n",
      "1044/1044 [==============================] - 11s 11ms/step - loss: 0.3806 - val_loss: 0.9297\n",
      "Epoch 7/10\n",
      "1044/1044 [==============================] - 11s 11ms/step - loss: 0.3794 - val_loss: 0.9563\n",
      "Epoch 8/10\n",
      "1044/1044 [==============================] - 11s 11ms/step - loss: 0.3692 - val_loss: 0.9829\n",
      "Epoch 9/10\n",
      "1044/1044 [==============================] - 11s 11ms/step - loss: 0.3556 - val_loss: 0.9901\n",
      "Epoch 10/10\n",
      "1044/1044 [==============================] - 11s 11ms/step - loss: 0.3559 - val_loss: 0.9928\n",
      "Train on 1031 samples, validate on 18 samples\n",
      "Epoch 1/10\n",
      "1031/1031 [==============================] - 13s 12ms/step - loss: 0.4920 - val_loss: 0.4757\n",
      "Epoch 2/10\n",
      "1031/1031 [==============================] - 12s 12ms/step - loss: 0.4567 - val_loss: 0.4576\n",
      "Epoch 3/10\n",
      "1031/1031 [==============================] - 12s 11ms/step - loss: 0.3950 - val_loss: 0.3824\n",
      "Epoch 4/10\n",
      "1031/1031 [==============================] - 12s 11ms/step - loss: 0.3669 - val_loss: 0.2410\n",
      "Epoch 5/10\n",
      "1031/1031 [==============================] - 12s 12ms/step - loss: 0.3739 - val_loss: 0.1643\n",
      "Epoch 6/10\n",
      "1031/1031 [==============================] - 11s 11ms/step - loss: 0.3401 - val_loss: 0.1240\n",
      "Epoch 7/10\n",
      "1031/1031 [==============================] - 11s 11ms/step - loss: 0.3356 - val_loss: 0.0980\n",
      "Epoch 8/10\n",
      "1031/1031 [==============================] - 11s 11ms/step - loss: 0.3426 - val_loss: 0.0910\n",
      "Epoch 9/10\n",
      "1031/1031 [==============================] - 12s 11ms/step - loss: 0.3444 - val_loss: 0.0792\n",
      "Epoch 10/10\n",
      "1031/1031 [==============================] - 11s 11ms/step - loss: 0.3398 - val_loss: 0.0759\n",
      "Train on 999 samples, validate on 50 samples\n",
      "Epoch 1/10\n",
      "999/999 [==============================] - 12s 12ms/step - loss: 0.4833 - val_loss: 0.2435\n",
      "Epoch 2/10\n",
      "999/999 [==============================] - 12s 12ms/step - loss: 0.4397 - val_loss: 0.0335\n",
      "Epoch 3/10\n",
      "999/999 [==============================] - 12s 12ms/step - loss: 0.4028 - val_loss: 0.1359\n",
      "Epoch 4/10\n",
      "999/999 [==============================] - 12s 12ms/step - loss: 0.3848 - val_loss: 0.1397\n",
      "Epoch 5/10\n",
      "999/999 [==============================] - 12s 12ms/step - loss: 0.3627 - val_loss: 0.1466\n",
      "Epoch 6/10\n",
      "999/999 [==============================] - 12s 12ms/step - loss: 0.3633 - val_loss: 0.0637\n",
      "Epoch 7/10\n",
      "999/999 [==============================] - 12s 12ms/step - loss: 0.3321 - val_loss: 0.0227\n",
      "Epoch 8/10\n",
      "999/999 [==============================] - 12s 12ms/step - loss: 0.3669 - val_loss: 0.0030\n",
      "Epoch 9/10\n",
      "999/999 [==============================] - 12s 12ms/step - loss: 0.3804 - val_loss: 0.0028\n",
      "Epoch 10/10\n",
      "999/999 [==============================] - 12s 12ms/step - loss: 0.3812 - val_loss: 0.0025\n",
      "Train on 1045 samples, validate on 4 samples\n",
      "Epoch 1/10\n",
      "1045/1045 [==============================] - 12s 12ms/step - loss: 0.4914 - val_loss: 0.3310\n",
      "Epoch 2/10\n",
      "1045/1045 [==============================] - 12s 11ms/step - loss: 0.4592 - val_loss: 0.0571\n",
      "Epoch 3/10\n",
      "1045/1045 [==============================] - 12s 11ms/step - loss: 0.4193 - val_loss: 0.0076\n",
      "Epoch 4/10\n",
      "1045/1045 [==============================] - 12s 11ms/step - loss: 0.4033 - val_loss: 0.0043\n",
      "Epoch 5/10\n",
      "1045/1045 [==============================] - 12s 12ms/step - loss: 0.3849 - val_loss: 0.0028\n",
      "Epoch 6/10\n",
      "1045/1045 [==============================] - 11s 11ms/step - loss: 0.3838 - val_loss: 0.0019\n",
      "Epoch 7/10\n",
      "1045/1045 [==============================] - 11s 11ms/step - loss: 0.3742 - val_loss: 0.0015\n",
      "Epoch 8/10\n",
      "1045/1045 [==============================] - 11s 11ms/step - loss: 0.3655 - val_loss: 0.0013\n",
      "Epoch 9/10\n",
      "1045/1045 [==============================] - 11s 11ms/step - loss: 0.3647 - val_loss: 0.0011\n",
      "Epoch 10/10\n",
      "1045/1045 [==============================] - 12s 11ms/step - loss: 0.3633 - val_loss: 0.0010\n",
      "Train on 1018 samples, validate on 31 samples\n",
      "Epoch 1/10\n",
      "1018/1018 [==============================] - 13s 12ms/step - loss: 0.4845 - val_loss: 0.5132\n",
      "Epoch 2/10\n",
      "1018/1018 [==============================] - 12s 11ms/step - loss: 0.4269 - val_loss: 0.5452\n",
      "Epoch 3/10\n",
      "1018/1018 [==============================] - 12s 11ms/step - loss: 0.3922 - val_loss: 0.5277\n",
      "Epoch 4/10\n",
      "1018/1018 [==============================] - 12s 12ms/step - loss: 0.3438 - val_loss: 0.5305\n",
      "Epoch 5/10\n",
      "1018/1018 [==============================] - 12s 11ms/step - loss: 0.3214 - val_loss: 0.4083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10\n",
      "1018/1018 [==============================] - 11s 11ms/step - loss: 0.3432 - val_loss: 0.5481\n",
      "Epoch 7/10\n",
      "1018/1018 [==============================] - 12s 11ms/step - loss: 0.3176 - val_loss: 0.5481\n",
      "Epoch 8/10\n",
      "1018/1018 [==============================] - 12s 12ms/step - loss: 0.3492 - val_loss: 0.5482\n",
      "Epoch 9/10\n",
      "1018/1018 [==============================] - 12s 11ms/step - loss: 0.3537 - val_loss: 0.5482\n",
      "Epoch 10/10\n",
      "1018/1018 [==============================] - 11s 11ms/step - loss: 0.3586 - val_loss: 0.5482\n",
      "Train on 1029 samples, validate on 20 samples\n",
      "Epoch 1/10\n",
      "1029/1029 [==============================] - 13s 12ms/step - loss: 0.4828 - val_loss: 0.5819\n",
      "Epoch 2/10\n",
      "1029/1029 [==============================] - 11s 11ms/step - loss: 0.4323 - val_loss: 0.5900\n",
      "Epoch 3/10\n",
      "1029/1029 [==============================] - 11s 11ms/step - loss: 0.3882 - val_loss: 0.5323\n",
      "Epoch 4/10\n",
      "1029/1029 [==============================] - 11s 11ms/step - loss: 0.3544 - val_loss: 0.4724\n",
      "Epoch 5/10\n",
      "1029/1029 [==============================] - 11s 11ms/step - loss: 0.3705 - val_loss: 0.4551\n",
      "Epoch 6/10\n",
      "1029/1029 [==============================] - 11s 11ms/step - loss: 0.3476 - val_loss: 0.4533\n",
      "Epoch 7/10\n",
      "1029/1029 [==============================] - 11s 11ms/step - loss: 0.3126 - val_loss: 0.4516\n",
      "Epoch 8/10\n",
      "1029/1029 [==============================] - 11s 11ms/step - loss: 0.3136 - val_loss: 0.4508\n",
      "Epoch 9/10\n",
      "1029/1029 [==============================] - 11s 11ms/step - loss: 0.3137 - val_loss: 0.4505\n",
      "Epoch 10/10\n",
      "1029/1029 [==============================] - 12s 11ms/step - loss: 0.3132 - val_loss: 0.4503\n",
      "Train on 1039 samples, validate on 10 samples\n",
      "Epoch 1/10\n",
      "1039/1039 [==============================] - 13s 12ms/step - loss: 0.4875 - val_loss: 0.4867\n",
      "Epoch 2/10\n",
      "1039/1039 [==============================] - 12s 11ms/step - loss: 0.4455 - val_loss: 0.4493\n",
      "Epoch 3/10\n",
      "1039/1039 [==============================] - 11s 11ms/step - loss: 0.4061 - val_loss: 0.5164\n",
      "Epoch 4/10\n",
      "1039/1039 [==============================] - 12s 11ms/step - loss: 0.3595 - val_loss: 0.7612\n",
      "Epoch 5/10\n",
      "1039/1039 [==============================] - 11s 11ms/step - loss: 0.3789 - val_loss: 0.9137\n",
      "Epoch 6/10\n",
      "1039/1039 [==============================] - 11s 11ms/step - loss: 0.3838 - val_loss: 0.9304\n",
      "Epoch 7/10\n",
      "1039/1039 [==============================] - 12s 11ms/step - loss: 0.3064 - val_loss: 0.7822\n",
      "Epoch 8/10\n",
      "1039/1039 [==============================] - 11s 11ms/step - loss: 0.2931 - val_loss: 0.5934\n",
      "Epoch 9/10\n",
      "1039/1039 [==============================] - 11s 11ms/step - loss: 0.2865 - val_loss: 0.5957\n",
      "Epoch 10/10\n",
      "1039/1039 [==============================] - 12s 11ms/step - loss: 0.2896 - val_loss: 0.5969\n",
      "Train on 966 samples, validate on 83 samples\n",
      "Epoch 1/10\n",
      "966/966 [==============================] - 13s 13ms/step - loss: 0.4908 - val_loss: 0.4642\n",
      "Epoch 2/10\n",
      "966/966 [==============================] - 12s 12ms/step - loss: 0.4438 - val_loss: 0.3531\n",
      "Epoch 3/10\n",
      "966/966 [==============================] - 12s 12ms/step - loss: 0.3843 - val_loss: 0.3582\n",
      "Epoch 4/10\n",
      "966/966 [==============================] - 12s 12ms/step - loss: 0.3650 - val_loss: 0.3926\n",
      "Epoch 5/10\n",
      "966/966 [==============================] - 12s 12ms/step - loss: 0.3452 - val_loss: 0.3106\n",
      "Epoch 6/10\n",
      "966/966 [==============================] - 12s 12ms/step - loss: 0.3121 - val_loss: 0.2866\n",
      "Epoch 7/10\n",
      "966/966 [==============================] - 12s 12ms/step - loss: 0.3258 - val_loss: 0.2907\n",
      "Epoch 8/10\n",
      "966/966 [==============================] - 12s 12ms/step - loss: 0.3149 - val_loss: 0.3444\n",
      "Epoch 9/10\n",
      "966/966 [==============================] - 12s 12ms/step - loss: 0.3053 - val_loss: 0.3818\n",
      "Epoch 10/10\n",
      "966/966 [==============================] - 12s 12ms/step - loss: 0.3068 - val_loss: 0.3739\n",
      "Train on 1029 samples, validate on 20 samples\n",
      "Epoch 1/10\n",
      "1029/1029 [==============================] - 13s 13ms/step - loss: 0.4918 - val_loss: 0.4863\n",
      "Epoch 2/10\n",
      "1029/1029 [==============================] - 12s 11ms/step - loss: 0.4552 - val_loss: 0.4548\n",
      "Epoch 3/10\n",
      "1029/1029 [==============================] - 12s 11ms/step - loss: 0.4328 - val_loss: 0.4509\n",
      "Epoch 4/10\n",
      "1029/1029 [==============================] - 12s 11ms/step - loss: 0.4254 - val_loss: 0.4506\n",
      "Epoch 5/10\n",
      "1029/1029 [==============================] - 12s 11ms/step - loss: 0.4244 - val_loss: 0.4505\n",
      "Epoch 6/10\n",
      "1029/1029 [==============================] - 12s 11ms/step - loss: 0.4224 - val_loss: 0.4504\n",
      "Epoch 7/10\n",
      "1029/1029 [==============================] - 12s 11ms/step - loss: 0.4221 - val_loss: 0.4985\n",
      "Epoch 8/10\n",
      "1029/1029 [==============================] - 12s 11ms/step - loss: 0.4233 - val_loss: 0.4991\n",
      "Epoch 9/10\n",
      "1029/1029 [==============================] - 11s 11ms/step - loss: 0.4229 - val_loss: 0.4995\n",
      "Epoch 10/10\n",
      "1029/1029 [==============================] - 11s 11ms/step - loss: 0.4227 - val_loss: 0.4996\n",
      "Train on 1047 samples, validate on 2 samples\n",
      "Epoch 1/10\n",
      "1047/1047 [==============================] - 13s 13ms/step - loss: 0.4945 - val_loss: 0.3463\n",
      "Epoch 2/10\n",
      "1047/1047 [==============================] - 12s 11ms/step - loss: 0.4635 - val_loss: 0.0637\n",
      "Epoch 3/10\n",
      "1047/1047 [==============================] - 12s 11ms/step - loss: 0.4221 - val_loss: 0.0167\n",
      "Epoch 4/10\n",
      "1047/1047 [==============================] - 12s 11ms/step - loss: 0.3823 - val_loss: 0.0069\n",
      "Epoch 5/10\n",
      "1047/1047 [==============================] - 12s 11ms/step - loss: 0.3566 - val_loss: 0.0043\n",
      "Epoch 6/10\n",
      "1047/1047 [==============================] - 12s 11ms/step - loss: 0.3626 - val_loss: 0.0033\n",
      "Epoch 7/10\n",
      "1047/1047 [==============================] - 12s 11ms/step - loss: 0.3225 - val_loss: 0.0031\n",
      "Epoch 8/10\n",
      "1047/1047 [==============================] - 12s 11ms/step - loss: 0.3017 - val_loss: 0.0031\n",
      "Epoch 9/10\n",
      "1047/1047 [==============================] - 12s 11ms/step - loss: 0.2997 - val_loss: 0.0025\n",
      "Epoch 10/10\n",
      "1047/1047 [==============================] - 12s 11ms/step - loss: 0.2912 - val_loss: 0.0021\n",
      "Train on 1034 samples, validate on 15 samples\n",
      "Epoch 1/10\n",
      "1034/1034 [==============================] - 13s 13ms/step - loss: 0.4912 - val_loss: 0.3840\n",
      "Epoch 2/10\n",
      "1034/1034 [==============================] - 12s 11ms/step - loss: 0.4473 - val_loss: 0.2189\n",
      "Epoch 3/10\n",
      "1034/1034 [==============================] - 12s 11ms/step - loss: 0.3964 - val_loss: 0.1903\n",
      "Epoch 4/10\n",
      "1034/1034 [==============================] - 11s 11ms/step - loss: 0.3742 - val_loss: 0.2409\n",
      "Epoch 5/10\n",
      "1034/1034 [==============================] - 12s 11ms/step - loss: 0.3407 - val_loss: 0.1938\n",
      "Epoch 6/10\n",
      "1034/1034 [==============================] - 12s 11ms/step - loss: 0.3097 - val_loss: 0.1944\n",
      "Epoch 7/10\n",
      "1034/1034 [==============================] - 12s 11ms/step - loss: 0.3101 - val_loss: 0.1985\n",
      "Epoch 8/10\n",
      "1034/1034 [==============================] - 12s 11ms/step - loss: 0.2999 - val_loss: 0.0674\n",
      "Epoch 9/10\n",
      "1034/1034 [==============================] - 12s 11ms/step - loss: 0.3157 - val_loss: 0.0674\n",
      "Epoch 10/10\n",
      "1034/1034 [==============================] - 12s 11ms/step - loss: 0.3123 - val_loss: 0.0676\n",
      "Train on 983 samples, validate on 66 samples\n",
      "Epoch 1/10\n",
      "983/983 [==============================] - 13s 14ms/step - loss: 0.5006 - val_loss: 0.4986\n",
      "Epoch 2/10\n",
      "983/983 [==============================] - 12s 12ms/step - loss: 0.4851 - val_loss: 0.3590\n",
      "Epoch 3/10\n",
      "983/983 [==============================] - 12s 12ms/step - loss: 0.4138 - val_loss: 0.5915\n",
      "Epoch 4/10\n",
      "983/983 [==============================] - 12s 12ms/step - loss: 0.3808 - val_loss: 0.7603\n",
      "Epoch 5/10\n",
      "983/983 [==============================] - 12s 12ms/step - loss: 0.3637 - val_loss: 0.6479\n",
      "Epoch 6/10\n",
      "983/983 [==============================] - 12s 12ms/step - loss: 0.3506 - val_loss: 0.6642\n",
      "Epoch 7/10\n",
      "983/983 [==============================] - 12s 12ms/step - loss: 0.3504 - val_loss: 0.7438\n",
      "Epoch 8/10\n",
      "983/983 [==============================] - 12s 12ms/step - loss: 0.3695 - val_loss: 0.7713\n",
      "Epoch 9/10\n",
      "983/983 [==============================] - 12s 12ms/step - loss: 0.3691 - val_loss: 0.7810\n",
      "Epoch 10/10\n",
      "983/983 [==============================] - 12s 12ms/step - loss: 0.3677 - val_loss: 0.7869\n",
      "Train on 1044 samples, validate on 5 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1044/1044 [==============================] - 13s 13ms/step - loss: 0.4932 - val_loss: 0.3443\n",
      "Epoch 2/10\n",
      "1044/1044 [==============================] - 12s 11ms/step - loss: 0.4558 - val_loss: 0.0438\n",
      "Epoch 3/10\n",
      "1044/1044 [==============================] - 12s 11ms/step - loss: 0.4401 - val_loss: 0.0114\n",
      "Epoch 4/10\n",
      "1044/1044 [==============================] - 12s 11ms/step - loss: 0.4294 - val_loss: 0.0064\n",
      "Epoch 5/10\n",
      "1044/1044 [==============================] - 11s 11ms/step - loss: 0.3829 - val_loss: 0.0053\n",
      "Epoch 6/10\n",
      "1044/1044 [==============================] - 12s 11ms/step - loss: 0.3840 - val_loss: 0.0052\n",
      "Epoch 7/10\n",
      "1044/1044 [==============================] - 12s 11ms/step - loss: 0.3842 - val_loss: 0.0046\n",
      "Epoch 8/10\n",
      "1044/1044 [==============================] - 12s 12ms/step - loss: 0.3826 - val_loss: 0.0037\n",
      "Epoch 9/10\n",
      "1044/1044 [==============================] - 12s 11ms/step - loss: 0.3822 - val_loss: 0.0031\n",
      "Epoch 10/10\n",
      "1044/1044 [==============================] - 11s 11ms/step - loss: 0.3820 - val_loss: 0.0024\n",
      "Train on 1024 samples, validate on 25 samples\n",
      "Epoch 1/10\n",
      "1024/1024 [==============================] - 13s 13ms/step - loss: 0.4893 - val_loss: 0.3875\n",
      "Epoch 2/10\n",
      "1024/1024 [==============================] - 11s 11ms/step - loss: 0.4486 - val_loss: 0.0249\n",
      "Epoch 3/10\n",
      "1024/1024 [==============================] - 11s 11ms/step - loss: 0.4056 - val_loss: 0.5530\n",
      "Epoch 4/10\n",
      "1024/1024 [==============================] - 11s 11ms/step - loss: 0.4323 - val_loss: 0.5973\n",
      "Epoch 5/10\n",
      "1024/1024 [==============================] - 12s 11ms/step - loss: 0.4232 - val_loss: 0.6443\n",
      "Epoch 6/10\n",
      "1024/1024 [==============================] - 12s 11ms/step - loss: 0.4128 - val_loss: 0.6537\n",
      "Epoch 7/10\n",
      "1024/1024 [==============================] - 12s 11ms/step - loss: 0.4072 - val_loss: 0.6557\n",
      "Epoch 8/10\n",
      "1024/1024 [==============================] - 12s 11ms/step - loss: 0.4083 - val_loss: 0.6568\n",
      "Epoch 9/10\n",
      "1024/1024 [==============================] - 12s 11ms/step - loss: 0.4007 - val_loss: 0.5870\n",
      "Epoch 10/10\n",
      "1024/1024 [==============================] - 12s 11ms/step - loss: 0.3769 - val_loss: 0.5049\n",
      "Train on 989 samples, validate on 60 samples\n",
      "Epoch 1/10\n",
      "989/989 [==============================] - 13s 14ms/step - loss: 0.4942 - val_loss: 0.5057\n",
      "Epoch 2/10\n",
      "989/989 [==============================] - 11s 12ms/step - loss: 0.4546 - val_loss: 0.5997\n",
      "Epoch 3/10\n",
      "989/989 [==============================] - 11s 12ms/step - loss: 0.3802 - val_loss: 0.7775\n",
      "Epoch 4/10\n",
      "989/989 [==============================] - 12s 12ms/step - loss: 0.3248 - val_loss: 0.8162\n",
      "Epoch 5/10\n",
      "989/989 [==============================] - 12s 12ms/step - loss: 0.3099 - val_loss: 0.6747\n",
      "Epoch 6/10\n",
      "989/989 [==============================] - 12s 12ms/step - loss: 0.3046 - val_loss: 0.6800\n",
      "Epoch 7/10\n",
      "989/989 [==============================] - 12s 12ms/step - loss: 0.3033 - val_loss: 0.6980\n",
      "Epoch 8/10\n",
      "989/989 [==============================] - 11s 12ms/step - loss: 0.3017 - val_loss: 0.6986\n",
      "Epoch 9/10\n",
      "989/989 [==============================] - 12s 12ms/step - loss: 0.3024 - val_loss: 0.7155\n",
      "Epoch 10/10\n",
      "989/989 [==============================] - 12s 12ms/step - loss: 0.3022 - val_loss: 0.7157\n",
      "Train on 943 samples, validate on 106 samples\n",
      "Epoch 1/10\n",
      "943/943 [==============================] - 14s 15ms/step - loss: 0.4816 - val_loss: 0.7176\n",
      "Epoch 2/10\n",
      "943/943 [==============================] - 12s 13ms/step - loss: 0.3890 - val_loss: 0.9522\n",
      "Epoch 3/10\n",
      "943/943 [==============================] - 12s 13ms/step - loss: 0.3391 - val_loss: 0.9644\n",
      "Epoch 4/10\n",
      "943/943 [==============================] - 12s 13ms/step - loss: 0.3406 - val_loss: 0.9669\n",
      "Epoch 5/10\n",
      "943/943 [==============================] - 12s 13ms/step - loss: 0.3414 - val_loss: 0.9679\n",
      "Epoch 6/10\n",
      "943/943 [==============================] - 12s 13ms/step - loss: 0.3404 - val_loss: 0.9687\n",
      "Epoch 7/10\n",
      "943/943 [==============================] - 12s 13ms/step - loss: 0.3409 - val_loss: 0.9697\n",
      "Epoch 8/10\n",
      "943/943 [==============================] - 12s 13ms/step - loss: 0.3405 - val_loss: 0.9701\n",
      "Epoch 9/10\n",
      "943/943 [==============================] - 12s 13ms/step - loss: 0.3402 - val_loss: 0.9704\n",
      "Epoch 10/10\n",
      "943/943 [==============================] - 12s 13ms/step - loss: 0.3400 - val_loss: 0.9706\n",
      "Train on 954 samples, validate on 95 samples\n",
      "Epoch 1/10\n",
      "954/954 [==============================] - 14s 15ms/step - loss: 0.4846 - val_loss: 0.6535\n",
      "Epoch 2/10\n",
      "954/954 [==============================] - 12s 13ms/step - loss: 0.4042 - val_loss: 0.9236\n",
      "Epoch 3/10\n",
      "954/954 [==============================] - 12s 12ms/step - loss: 0.3746 - val_loss: 0.9247\n",
      "Epoch 4/10\n",
      "954/954 [==============================] - 12s 13ms/step - loss: 0.3461 - val_loss: 0.9443\n",
      "Epoch 5/10\n",
      "954/954 [==============================] - 12s 12ms/step - loss: 0.3367 - val_loss: 0.8953\n",
      "Epoch 6/10\n",
      "954/954 [==============================] - 12s 12ms/step - loss: 0.3319 - val_loss: 0.8758\n",
      "Epoch 7/10\n",
      "954/954 [==============================] - 12s 12ms/step - loss: 0.3282 - val_loss: 0.8536\n",
      "Epoch 8/10\n",
      "954/954 [==============================] - 12s 12ms/step - loss: 0.3290 - val_loss: 0.8540\n",
      "Epoch 9/10\n",
      "954/954 [==============================] - 12s 12ms/step - loss: 0.3266 - val_loss: 0.8399\n",
      "Epoch 10/10\n",
      "954/954 [==============================] - 12s 12ms/step - loss: 0.3268 - val_loss: 0.8244\n",
      "Train on 898 samples, validate on 151 samples\n",
      "Epoch 1/10\n",
      "898/898 [==============================] - 14s 16ms/step - loss: 0.4575 - val_loss: 0.8181\n",
      "Epoch 2/10\n",
      "898/898 [==============================] - 12s 14ms/step - loss: 0.3698 - val_loss: 0.8580\n",
      "Epoch 3/10\n",
      "898/898 [==============================] - 12s 14ms/step - loss: 0.3589 - val_loss: 0.8592\n",
      "Epoch 4/10\n",
      "898/898 [==============================] - 12s 14ms/step - loss: 0.3538 - val_loss: 0.8597\n",
      "Epoch 5/10\n",
      "898/898 [==============================] - 12s 14ms/step - loss: 0.3498 - val_loss: 0.8600\n",
      "Epoch 6/10\n",
      "898/898 [==============================] - 12s 14ms/step - loss: 0.3480 - val_loss: 0.8601\n",
      "Epoch 7/10\n",
      "898/898 [==============================] - 12s 14ms/step - loss: 0.3473 - val_loss: 0.8602\n",
      "Epoch 8/10\n",
      "898/898 [==============================] - 12s 14ms/step - loss: 0.3450 - val_loss: 0.8602\n",
      "Epoch 9/10\n",
      "898/898 [==============================] - 12s 13ms/step - loss: 0.3463 - val_loss: 0.8603\n",
      "Epoch 10/10\n",
      "898/898 [==============================] - 12s 13ms/step - loss: 0.3469 - val_loss: 0.8603\n",
      "Train on 950 samples, validate on 99 samples\n",
      "Epoch 1/10\n",
      "950/950 [==============================] - 14s 15ms/step - loss: 0.4783 - val_loss: 0.6379\n",
      "Epoch 2/10\n",
      "950/950 [==============================] - 12s 12ms/step - loss: 0.4116 - val_loss: 0.9229\n",
      "Epoch 3/10\n",
      "950/950 [==============================] - 12s 13ms/step - loss: 0.3862 - val_loss: 0.9750\n",
      "Epoch 4/10\n",
      "950/950 [==============================] - 12s 13ms/step - loss: 0.3366 - val_loss: 0.9764\n",
      "Epoch 5/10\n",
      "950/950 [==============================] - 12s 12ms/step - loss: 0.3452 - val_loss: 0.9768\n",
      "Epoch 6/10\n",
      "950/950 [==============================] - 12s 13ms/step - loss: 0.3326 - val_loss: 0.9782\n",
      "Epoch 7/10\n",
      "950/950 [==============================] - 12s 13ms/step - loss: 0.3197 - val_loss: 0.9785\n",
      "Epoch 8/10\n",
      "950/950 [==============================] - 12s 13ms/step - loss: 0.3215 - val_loss: 0.9786\n",
      "Epoch 9/10\n",
      "950/950 [==============================] - 12s 13ms/step - loss: 0.3129 - val_loss: 0.9788\n",
      "Epoch 10/10\n",
      "950/950 [==============================] - 12s 13ms/step - loss: 0.3165 - val_loss: 0.9788\n",
      "Train on 986 samples, validate on 63 samples\n",
      "Epoch 1/10\n",
      "986/986 [==============================] - 14s 14ms/step - loss: 0.4958 - val_loss: 0.4593\n",
      "Epoch 2/10\n",
      "986/986 [==============================] - 12s 12ms/step - loss: 0.4712 - val_loss: 0.1997\n",
      "Epoch 3/10\n",
      "986/986 [==============================] - 12s 12ms/step - loss: 0.4234 - val_loss: 0.1562\n",
      "Epoch 4/10\n",
      "986/986 [==============================] - 12s 12ms/step - loss: 0.4100 - val_loss: 0.1462\n",
      "Epoch 5/10\n",
      "986/986 [==============================] - 12s 12ms/step - loss: 0.4011 - val_loss: 0.1471\n",
      "Epoch 6/10\n",
      "986/986 [==============================] - 12s 12ms/step - loss: 0.4035 - val_loss: 0.1465\n",
      "Epoch 7/10\n",
      "986/986 [==============================] - 12s 12ms/step - loss: 0.4029 - val_loss: 0.1458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10\n",
      "986/986 [==============================] - 12s 12ms/step - loss: 0.4025 - val_loss: 0.1454\n",
      "Epoch 9/10\n",
      "986/986 [==============================] - 12s 12ms/step - loss: 0.4023 - val_loss: 0.1448\n",
      "Epoch 10/10\n",
      "986/986 [==============================] - 12s 12ms/step - loss: 0.4032 - val_loss: 0.1445\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "ufunc 'add' did not contain a loop with signature matching types dtype('<U12') dtype('<U12') dtype('<U12')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-7788c0994837>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mRecordingAnalysis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDetectDiscernAnomalyNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Sitng'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Stndg'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetaData\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-8-44682f30d8f8>\u001b[0m in \u001b[0;36mDetectDiscernAnomalyNN\u001b[1;34m(tasks, segment, binary, anomaly, metaData)\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 167\u001b[1;33m                     \u001b[0mRecordings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRecordings\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mrec\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    168\u001b[0m                     \u001b[0mSubjects\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSubjects\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mrecsub\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m                     \u001b[0mScores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mScores\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mrecsub\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: ufunc 'add' did not contain a loop with signature matching types dtype('<U12') dtype('<U12') dtype('<U12')"
     ]
    }
   ],
   "source": [
    "RecordingAnalysis = DetectDiscernAnomalyNN(['Sitng', 'Stndg'], True, True, True, metaData)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
