{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "import pickle\n",
    "from scipy.stats import skew, kurtosis, pearsonr\n",
    "from scipy.signal import butter, welch, filtfilt, resample\n",
    "import copy\n",
    "import time\n",
    "import datetime\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "from PreprocessFcns import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set path to folder containing Subject Records\n",
    "path = r'//FS2.smpp.local\\\\RTO\\\\CIS-PD Study\\MJFF Curation\\Finalized Dataset'\n",
    "# Set path to Destination Folder\n",
    "dest = r'//FS2.smpp.local\\\\RTO\\\\CIS-PD Study\\Patient Record Correlation'\n",
    "#---------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Medication Reports\n",
    "table_med = 'Table10.csv'\n",
    "dest_ext_med = 'Medication Reports'\n",
    "file_name_med = 'med_timepoints.csv'\n",
    "\n",
    "# Symptom Reports\n",
    "table_symt = 'Table11.csv'\n",
    "dest_ext_symt = 'Symptom Reports'\n",
    "file_name_symt = 'symt_timepoints.csv'\n",
    "\n",
    "# Diaries\n",
    "table_diar = 'Table12.csv'\n",
    "dest_ext_diar = 'Diaries'\n",
    "file_name_diar = 'diar_timepoints.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTimestampsPaths(timepoints_med, timepoints_symt, timepoints_diar):\n",
    "    \n",
    "    # Initialize Empty Lists for Each Necessary Piece of Information from Each Record\n",
    "    StartTimestamps = []\n",
    "    EndTimestamps = []\n",
    "    SaveFilePaths = []\n",
    "    \n",
    "    \n",
    "    StartTimes = timepoints_med.apply(lambda row: row.Timestamp + pd.Timedelta(unit = 'minute', value = -30), axis = 1)\n",
    "    EndTimes = timepoints_med.apply(lambda row: row.Timestamp + pd.Timedelta(unit = 'minute', value = 30), axis = 1)\n",
    "    SavePaths = timepoints_med.apply(lambda row: os.path.join(dest, dest_ext_med, str(row.SubjID), \n",
    "                                                                                  str(row.Timestamp)[:7], \n",
    "                                                                                  str(row.Timestamp)[8:10],\n",
    "                                                                                  str(row.Timestamp)[11:13] +\n",
    "                                                                                  str(row.Timestamp)[14:16] +\n",
    "                                                                                  str(row.Timestamp)[17:] + '.csv'), axis = 1)\n",
    "    StartTimestamps = StartTimestamps + list(StartTimes)\n",
    "    EndTimestamps = EndTimestamps + list(EndTimes)\n",
    "    SaveFilePaths = SaveFilePaths + list(SavePaths)\n",
    "    \n",
    "    StartTimes = timepoints_symt.apply(lambda row: row.Timestamp + pd.Timedelta(unit = 'minute', value = -30), axis = 1)\n",
    "    EndTimes = timepoints_symt.apply(lambda row: row.Timestamp, axis = 1)\n",
    "    SavePaths = timepoints_symt.apply(lambda row: os.path.join(dest, dest_ext_symt, str(row.SubjID), \n",
    "                                                                                   str(row.Timestamp)[:7], \n",
    "                                                                                   str(row.Timestamp)[8:10],\n",
    "                                                                                   str(row.Timestamp)[11:13] +\n",
    "                                                                                   str(row.Timestamp)[14:16] +\n",
    "                                                                                   str(row.Timestamp)[17:] + '.csv'),axis = 1)\n",
    "    StartTimestamps = StartTimestamps + list(StartTimes)\n",
    "    EndTimestamps = EndTimestamps + list(EndTimes)\n",
    "    SaveFilePaths = SaveFilePaths + list(SavePaths)\n",
    "    \n",
    "    StartTimes = timepoints_diar.apply(lambda row: row.Timestamp + pd.Timedelta(unit = 'minute', value = -30), axis = 1)\n",
    "    EndTimes = timepoints_diar.apply(lambda row: row.Timestamp, axis = 1)\n",
    "    SavePaths = timepoints_diar.apply(lambda row: os.path.join(dest, dest_ext_diar, str(row.SubjID), \n",
    "                                                                                   str(row.Timestamp)[:7], \n",
    "                                                                                   str(row.Timestamp)[8:10],\n",
    "                                                                                   str(row.Timestamp)[11:13] +\n",
    "                                                                                   str(row.Timestamp)[14:16] +\n",
    "                                                                                   str(row.Timestamp)[17:] + '.csv'),axis = 1)\n",
    "    StartTimestamps = StartTimestamps + list(StartTimes)\n",
    "    EndTimestamps = EndTimestamps + list(EndTimes)\n",
    "    SaveFilePaths = SaveFilePaths + list(SavePaths)\n",
    "    \n",
    "    return StartTimestamps, EndTimestamps, SaveFilePaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Consolidated DataFrames\n",
    "timepoints_med = pd.read_csv(os.path.join(dest, dest_ext_med, file_name_med), parse_dates = [1])\n",
    "timepoints_symt = pd.read_csv(os.path.join(dest, dest_ext_symt, file_name_symt), parse_dates = [1])\n",
    "timepoints_diar = pd.read_csv(os.path.join(dest, dest_ext_diar, file_name_diar), parse_dates = [1])\n",
    "\n",
    "# Create List of the Watch Data Files in the Table8 Directory (not including the subdirectory)\n",
    "watch_dir = [f for f in os.listdir(os.path.join(path, 'Table8')) if os.path.isfile(os.path.join(path, 'Table8', f))]\n",
    "\n",
    "StartTimestamps, EndTimestamps, SaveFilePaths = getTimestampsPaths(timepoints_med, timepoints_symt, timepoints_diar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-208-61b10493e8b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m81\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'//FS2.smpp.local\\\\\\\\RTO\\\\\\\\CIS-PD Study\\\\Patient Record Correlation\\\\Medication Reports'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m             \u001b[0mempty_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFileNotFoundError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, tupleize_cols, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[0;32m   3018\u001b[0m                                  \u001b[0mdoublequote\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3019\u001b[0m                                  escapechar=escapechar, decimal=decimal)\n\u001b[1;32m-> 3020\u001b[1;33m         \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3021\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3022\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    185\u001b[0m                     \u001b[0mclose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m                 \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0m_fh\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhandles\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m                     \u001b[0m_fh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize Template Empty Data Frame From Which to Create Files\n",
    "empty_df = pd.DataFrame(columns = ['SubjID', 'Timestamp', 'X', 'Y', 'Z'])\n",
    "\n",
    "# Generate Empty Files Organized in Subdirectories to Append Time Interval Watch Data\n",
    "# 'if statements' Required Because Record Type Paths Have Different Character Numbers\n",
    "for file in SaveFilePaths:\n",
    "    \n",
    "    if file[:81] == '//FS2.smpp.local\\\\\\\\RTO\\\\\\\\CIS-PD Study\\\\Patient Record Correlation\\\\Medication Reports':\n",
    "        try:\n",
    "            empty_df.to_csv(file, index = False)\n",
    "        except(FileNotFoundError):\n",
    "            try:\n",
    "                os.mkdir(file[:97])\n",
    "                empty_df.to_csv(file, index = False)\n",
    "            except(FileNotFoundError):\n",
    "                try:\n",
    "                    os.mkdir(file[:94])\n",
    "                    os.mkdir(file[:97])\n",
    "                    empty_df.to_csv(file, index = False)\n",
    "                except(FileNotFoundError):\n",
    "                    os.mkdir(file[:86])\n",
    "                    os.mkdir(file[:94])\n",
    "                    os.mkdir(file[:97])\n",
    "                    empty_df.to_csv(file, index = False)\n",
    "\n",
    "    if file[:78] == '//FS2.smpp.local\\\\\\\\RTO\\\\\\\\CIS-PD Study\\\\Patient Record Correlation\\\\Symptom Reports':\n",
    "        try:\n",
    "            empty_df.to_csv(file, index = False)\n",
    "        except(FileNotFoundError):\n",
    "            try:\n",
    "                os.mkdir(file[:94])\n",
    "                empty_df.to_csv(file, index = False)\n",
    "            except(FileNotFoundError):\n",
    "                try:\n",
    "                    os.mkdir(file[:91])\n",
    "                    os.mkdir(file[:94])\n",
    "                    empty_df.to_csv(file, index = False)\n",
    "                except(FileNotFoundError):\n",
    "                    os.mkdir(file[:83])\n",
    "                    os.mkdir(file[:91])\n",
    "                    os.mkdir(file[:94])\n",
    "                    empty_df.to_csv(file, index = False)\n",
    "\n",
    "    if file[:70] == '//FS2.smpp.local\\\\\\\\RTO\\\\\\\\CIS-PD Study\\\\Patient Record Correlation\\\\Diaries':\n",
    "        try:\n",
    "            empty_df.to_csv(file, index = False)\n",
    "        except(FileNotFoundError):\n",
    "            try:\n",
    "                os.mkdir(file[:86])\n",
    "                empty_df.to_csv(file, index = False)\n",
    "            except(FileNotFoundError):\n",
    "                try:\n",
    "                    os.mkdir(file[:83])\n",
    "                    os.mkdir(file[:86])\n",
    "                    empty_df.to_csv(file, index = False)\n",
    "                except(FileNotFoundError):\n",
    "                    os.mkdir(file[:75])\n",
    "                    os.mkdir(file[:83])\n",
    "                    os.mkdir(file[:86])\n",
    "                    empty_df.to_csv(file, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 hours 0 minutes 0 seconds\n",
      "0 hours 0 minutes 13 seconds\n",
      "0 hours 0 minutes 13 seconds\n",
      "0 hours 0 minutes 13 seconds\n",
      "0 hours 0 minutes 13 seconds\n",
      "0 hours 0 minutes 13 seconds\n",
      "0 hours 0 minutes 13 seconds\n",
      "0 hours 0 minutes 12 seconds\n",
      "0 hours 0 minutes 11 seconds\n",
      "0 hours 0 minutes 41 seconds\n",
      "0 hours 0 minutes 41 seconds\n",
      "0 hours 0 minutes 41 seconds\n",
      "0 hours 0 minutes 41 seconds\n",
      "0 hours 0 minutes 40 seconds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-210-83c54ea04174>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m             \u001b[1;31m# Get the Indices of the DataPoints in the Chunk that are Within the Record Time Range\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTimestamp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTimestamp\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTimestamp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTimestamp\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m             \u001b[1;31m# Save the Relevant Data Points to the Pre-Specified Record Path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[0;32m   3589\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3590\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3591\u001b[1;33m                 \u001b[0mmapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3593\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Start Time of Reading One Watch Data File\n",
    "s_time = time.time()\n",
    "\n",
    "for file in watch_dir:\n",
    "    \n",
    "    # Get the Subject and Month Corresponding to the Watch Data in the File\n",
    "    sub = file[7:11]\n",
    "    mon = file[12:19]\n",
    "    \n",
    "    # Only Consider File Paths Corresponding to the Relevant Watch File Subject and Month\n",
    "    # Look at Only Path Characters to 86 for Subject so Date/Time is not Considered\n",
    "    tempStart = [StartTimestamps[i] for i in range(len(StartTimestamps)) \n",
    "                 if sub in SaveFilePaths[i][:86] and mon in SaveFilePaths[i]]\n",
    "    tempEnd = [EndTimestamps[i] for i in range(len(EndTimestamps)) \n",
    "               if sub in SaveFilePaths[i][:86] and mon in SaveFilePaths[i]]\n",
    "    tempPath = [s for s in SaveFilePaths if sub in s[:86] and mon in s]\n",
    "    \n",
    "    # Read Watch Acc File in Chunks\n",
    "    watch_file_chunk = pd.read_csv(os.path.join(path, 'Table8', file), chunksize = 100000)\n",
    "    \n",
    "    chunk_time = time.time()\n",
    "    \n",
    "    # Look at One Chunk at a Time\n",
    "    for chunk in watch_file_chunk:\n",
    "        \n",
    "        # Get the Minimum and Maximum DataPoint Timestamp of Each Chunk\n",
    "        minTime, maxTime = pd.Timestamp(chunk.Timestamp.min()), pd.Timestamp(chunk.Timestamp.max())\n",
    "        \n",
    "        # Iterate through each Record\n",
    "        for s, e, p in zip(tempStart, tempEnd, tempPath):\n",
    "            \n",
    "            # Skip the Record if the Chunk does not Contain the Record Time Range\n",
    "            if s > maxTime or e < minTime:\n",
    "                continue\n",
    "                \n",
    "            # Get the Indices of the DataPoints in the Chunk that are Within the Record Time Range\n",
    "            indices = (chunk.Timestamp.apply(pd.Timestamp) > s) & (chunk.Timestamp.apply(pd.Timestamp) < e)\n",
    "            \n",
    "            # Save the Relevant Data Points to the Pre-Specified Record Path\n",
    "            chunk[indices].to_csv(path_or_buf = p, mode = 'a', index = False, header = False)\n",
    "            \n",
    "        # Track the Time to Iterate Through One Chunk\n",
    "        print(str(int(((time.time() - chunk_time) / 60) / 60)) + ' hours ' + \n",
    "              str(int(((time.time() - chunk_time) / 60) % 60)) + ' minutes ' + \n",
    "              str(int((time.time() - chunk_time) % 60)) + ' seconds')\n",
    "        chunk_time = time.time()\n",
    "    \n",
    "    # First File in the Table8 Directory Size = 1,665,829 KB\n",
    "    break\n",
    "\n",
    "# Print Time to Read One Watch Data File\n",
    "print(str(int(((time.time() - s_time) / 60) / 60)) + ' hours ' + \n",
    "      str(int(((time.time() - s_time) / 60) % 60)) + ' minutes ' + \n",
    "      str(int((time.time() - s_time) % 60)) + ' seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1043'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST CELL\n",
    "SaveFilePaths[-1][71:75]\n",
    "# IF THE LOOP DOESN'T RUN - MAKE SURE THE FUNCTION READS row.Timestamp AS A TIMESTAMP AND NOT A STRING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example Paths for Each Record Type\n",
    "'//FS2.smpp.local\\\\\\\\RTO\\\\\\\\CIS-PD Study\\\\Patient Record Correlation\\\\Medication Reports\\\\1004\\\\2017-06\\\\21\\\\142217.csv'\n",
    "'//FS2.smpp.local\\\\\\\\RTO\\\\\\\\CIS-PD Study\\\\Patient Record Correlation\\\\Diaries\\\\1043\\\\2017-08\\\\15\\\\120000.csv'\n",
    "'//FS2.smpp.local\\\\\\\\RTO\\\\\\\\CIS-PD Study\\\\Patient Record Correlation\\\\Symptom Reports\\\\1013\\\\2017-09\\\\06\\\\163350.csv'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
