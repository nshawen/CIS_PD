{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import bisect\n",
    "import datetime\n",
    "from dateutil.parser import parse\n",
    "import itertools\n",
    "from itertools import product\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "import nolds\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "from PreprocessFcns import *\n",
    "import pywt\n",
    "import random\n",
    "import scipy\n",
    "from scipy.fftpack import fft\n",
    "from scipy.signal import butter, welch, filtfilt, resample, find_peaks\n",
    "from scipy.stats import skew, kurtosis, entropy, pearsonr\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn import multiclass\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'//FS2.smpp.local\\\\RTO\\\\CIS-PD Study\\MJFF Curation\\Finalized Dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate task abbreviation dictionary\n",
    "ClinicTasks = {\n",
    "    'Stndg'    : 'Standing',\n",
    "    'Wlkg'     : 'Walking',\n",
    "    'WlkgCnt'  : 'Walking while counting',\n",
    "    'FtnR'     : 'Finger to nose--right hand',\n",
    "    'FtnL'     : 'Finger to nose--left hand',\n",
    "    'RamR'     : 'Alternating right hand movements',\n",
    "    'RamL'     : 'Alternating left hand movements',\n",
    "    'SitStand' : 'Sit to stand',\n",
    "    'Drwg'     : 'Drawing on a paper',\n",
    "    'Typg'     : 'Typing on a computer keyboard',\n",
    "    'NtsBts'   : 'Assembling nuts and bolts',\n",
    "    'Drnkg'    : 'Taking a glass of water and drinking',\n",
    "    'Sheets'   : 'Organizing sheets in a folder',\n",
    "    'Fldg'     : 'Folding towels',\n",
    "    'Sitng'    : 'Sitting'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate visit number dictionary\n",
    "VisitNumber = {\n",
    "    '2 Weeks: Time 0'   : 0,\n",
    "    '2 Weeks: Time 30'  : 1,\n",
    "    '2 Weeks: Time 60'  : 2,\n",
    "    '2 Weeks: Time 90'  : 3,\n",
    "    '2 Weeks: Time 120' : 4,\n",
    "    '2 Weeks: Time 150' : 5,\n",
    "    '1 Month'           : 6\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterMetaData(tasks):\n",
    "'''filter metadata file to remove empty data and unnecessary scores\n",
    "add necessary information including binary tremor scores\n",
    "\n",
    "tasks: list of tasks for which to retrieve metadata of'''\n",
    "\n",
    "    # open metadata containing scores for each symptom for each task completed\n",
    "    metaDataFull = pd.read_csv(os.path.join(path, 'Metadata Tables', 'Table4.csv'))\n",
    "    # isolate metadata corresponding to tasks of interest specified\n",
    "    indices = (x for x in range(len(metaDataFull)) if metaDataFull.TaskAbb.values[x] in tasks)\n",
    "    metaDataFull = metaDataFull.loc[indices]\n",
    "\n",
    "    SubjID = []\n",
    "    Visit = []\n",
    "    TaskAbb = []\n",
    "    AccFile = []\n",
    "    Tremor = []\n",
    "    for record in metaDataFull.iterrows():\n",
    "        # eliminate rows of metadata that contain nan values\n",
    "        if (type(record[1]['Side']) == float):\n",
    "            continue\n",
    "        if (np.isnan(record[1]['Tremor - ' + record[1]['Side']])):\n",
    "            continue\n",
    "        # build file name of the recording related to each piece of metadata\n",
    "        filename = (str(int(record[1]['SubjID'])) + '_' +\n",
    "                            str(VisitNumber[record[1]['Visit']]) + '_' + \n",
    "                            record[1]['TaskAbb'] + '.csv')\n",
    "        # add file name to file path for easy access\n",
    "        filepath = os.path.join(path, 'TaskAcc', filename)\n",
    "        # test is the recording file exists (not all metadata has related acceleration recording)\n",
    "        if not os.path.exists(filepath):\n",
    "            continue\n",
    "        SubjID = SubjID + [int(record[1]['SubjID'])]\n",
    "        Visit = Visit + [VisitNumber[record[1]['Visit']]]\n",
    "        TaskAbb = TaskAbb + [record[1]['TaskAbb']]\n",
    "        AccFile = AccFile + [filename]\n",
    "        # only concerned with tremor score on the side of subject wearing the apple watch\n",
    "        Tremor = Tremor + [int(record[1]['Tremor - ' + record[1]['Side']])]\n",
    "    # create column with binary tremor scores (symptomatic vs normal)\n",
    "    TremorBIN = [int(t > 0) for t in Tremor]\n",
    "    metaData = pd.DataFrame({'SubjID': SubjID, \n",
    "                             'Visit': Visit, \n",
    "                             'TaskAbb': TaskAbb,\n",
    "                             'AccFile': AccFile,\n",
    "                             'Tremor': Tremor,\n",
    "                             'TremorBIN': TremorBIN})\n",
    "    print('Records = ' + str(len(metaData)))\n",
    "    \n",
    "    return metaData\n",
    "    \n",
    "def formatInputNN(tasks, metaData, segment):\n",
    "'''generate arrays of data, labels, and metadata to train and analyze data\n",
    "filters to only contain anomalies (does not score non-anomalous clips in any way)\n",
    "\n",
    "tasks: list of tasks to consider\n",
    "metaData: variable saved after generation from function above\n",
    "segment: True or False - whether or not to consider full recording or segment into clips'''\n",
    "    \n",
    "    # set the threshold for which to consider clips anomalies\n",
    "    NormRMSE = 0.01\n",
    "    Data = []\n",
    "    Labels = []\n",
    "    Subjects = []\n",
    "    for record in metaData.iterrows():\n",
    "        # load acceleration recording according to information in row of metadata\n",
    "        recording = pd.read_csv(os.path.join(path, 'TaskAcc', record[1]['AccFile']), \n",
    "                                parse_dates = ['timestamp'])[['timestamp', 'x', 'y', 'z']]\n",
    "        recording.columns = ['Timestamp', 'X', 'Y', 'Z']\n",
    "        # recording not filtered - simply calculate magnitude from the axes\n",
    "        recording['Mag'] = np.sqrt((recording.X**2 + recording.Y**2 + recording.Z**2))\n",
    "        recording = recording.sort_values(by = 'Timestamp', axis = 0)\n",
    "        \n",
    "        if segment:\n",
    "            # similar to random forest model: group sets of data by proximity in timestamp windows\n",
    "            # to change segment window length, change time after tm.second modulo\n",
    "            recording['TimeWdw'] = [(tm - datetime.timedelta(minutes = 0,\n",
    "                                                             seconds = tm.second % 1.5,\n",
    "                                                             microseconds = tm.microsecond)) \n",
    "                                    for tm in recording.Timestamp]\n",
    "            # set index of data as time in epoch time after first value of recording\n",
    "            recording['TimeIdx'] = (recording.Timestamp.values - \n",
    "                                    recording.Timestamp.values[0]).astype('timedelta64[ms]').astype(int)\n",
    "            recording = recording.set_index('TimeIdx')\n",
    "            # isolate each clip according to grouping with 50% overlap between clips\n",
    "            # to change segment window length, change time in timedelta\n",
    "            for t in recording.TimeWdw.unique():\n",
    "                clip = recording.loc[(recording.TimeWdw == t) | \n",
    "                                     (recording.TimeWdw == (t + np.timedelta64(1500, 'ms')))]\n",
    "                # clips clips containing much less data than necessary(50Hz so about 150 expected for 3 seconds)\n",
    "                if len(clip) < 120:\n",
    "                    continue\n",
    "                # if tasks are siting or standing (most of the time they should be) skip if not anomaly\n",
    "                # only want model to train to tell difference between symptomatic and normal anomaly\n",
    "                if ((tasks == ['Sitng', 'Stndg']) or \n",
    "                    (tasks == ['Stndg', 'Sitng']) or \n",
    "                    (tasks == ['Sitng']) or \n",
    "                    (tasks == ['Stndg'])) and ((np.sqrt(np.mean((clip.Mag - np.mean(clip.Mag))**2))) < NormRMSE):\n",
    "                    continue\n",
    "                # upsample all clips (axes independently) to fit normally into array\n",
    "                fx = scipy.interpolate.interp1d(range(len(clip)), clip.X.values)\n",
    "                fy = scipy.interpolate.interp1d(range(len(clip)), clip.Y.values)\n",
    "                fz = scipy.interpolate.interp1d(range(len(clip)), clip.Z.values)\n",
    "                clipX = fx(np.linspace(start = 0, stop = len(clip) - 1, num = 500))\n",
    "                clipY = fy(np.linspace(start = 0, stop = len(clip) - 1, num = 500))\n",
    "                clipZ = fz(np.linspace(start = 0, stop = len(clip) - 1, num = 500))\n",
    "                # manually shape resampled clip data into a rectangular array\n",
    "                datasteps = []\n",
    "                for dpx, dpy, dpz in zip(clipX, clipY, clipZ):\n",
    "                    datasteps = datasteps + [[dpx, dpy, dpz]]\n",
    "                Data = Data + [datasteps]\n",
    "                # add relevant metadata to correlate to acceleration data in array\n",
    "                Labels = Labels + [record[1]['TremorBIN']]\n",
    "                Subjects = Subjects + [record[1]['SubjID']]\n",
    "                \n",
    "        else:\n",
    "            # upsample recordings to 1000\n",
    "            fx = scipy.interpolate.interp1d(range(len(recording)), recording.X.values)\n",
    "            fy = scipy.interpolate.interp1d(range(len(recording)), recording.Y.values)\n",
    "            fz = scipy.interpolate.interp1d(range(len(recording)), recording.Z.values)\n",
    "            clipX = fx(np.linspace(start = 0, stop = len(recording) - 1, num = 1000))\n",
    "            clipY = fy(np.linspace(start = 0, stop = len(recording) - 1, num = 1000))\n",
    "            clipZ = fz(np.linspace(start = 0, stop = len(recording) - 1, num = 1000))\n",
    "            # manually shape resampled clip data into a rectangular array\n",
    "            datasteps = []\n",
    "            for dpx, dpy, dpz in zip(clipX, clipY, clipZ):\n",
    "                datasteps = datasteps + [[dpx, dpy, dpz]]\n",
    "            Data = Data + [datasteps]\n",
    "            # add relevant metadata to correlate to acceleration data in array\n",
    "            Labels = Labels + [record[1]['TremorBIN']]\n",
    "            Subjects = Subjects + [record[1]['SubjID']]\n",
    "\n",
    "    Data = np.array(Data)\n",
    "    Labels = np.array(Labels)\n",
    "    Subjects = np.array(Subjects)\n",
    "    print('(Samples, Timesteps, Features (Axes)) = ' + str(Data.shape))\n",
    "    print('Labels = ' + str(len(Labels)))\n",
    "    print('Subjects = ' + str(len(set(Subjects))))\n",
    "    \n",
    "    return Data, Labels, Subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records = 265\n",
      "(Samples, Timesteps, Features (Axes)) = (265, 1000, 3)\n",
      "Labels = 265\n",
      "Subjects = 23\n"
     ]
    }
   ],
   "source": [
    "metaData = filterMetaData(['Wlkg', 'WlkgCnt'])\n",
    "Data, Labels, Subjects = formatInputNN(['Wlkg', 'WlkgCnt'], metaData, segment = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Subject: 1003\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected lstm_231_input to have shape (500, 3) but got array with shape (1000, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-285-03c6106cbffd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         history = model.fit(trainData, trainLab, epochs = 10, batch_size = int(len(trainInd) / 20), \n\u001b[1;32m---> 20\u001b[1;33m                             validation_data = (testData, testLab))\n\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[1;32mexcept\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 952\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m    953\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 751\u001b[1;33m             exception_prefix='input')\n\u001b[0m\u001b[0;32m    752\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    136\u001b[0m                             \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m                             str(data_shape))\n\u001b[0m\u001b[0;32m    139\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected lstm_231_input to have shape (500, 3) but got array with shape (1000, 3)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1152x1152 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grouper = LeaveOneGroupOut()\n",
    "valsubs = []\n",
    "plt.figure(figsize = (16, 16))\n",
    "# train and validate neural network by individual subject using leave one group out method\n",
    "for trainInd, testInd in grouper.split(Data, Labels, groups = Subjects):\n",
    "    trainData = Data[trainInd]\n",
    "    trainLab = Labels[trainInd]\n",
    "    testData = Data[testInd]\n",
    "    testLab = Labels[testInd]\n",
    "    subject = int(np.unique(Subjects[testInd]))\n",
    "    # validation subjects - list of each subject in order of validation (to use as legend of ROC curve plot)\n",
    "    valsubs = valsubs + [subject]\n",
    "    \n",
    "    print('Validation Subject: ' + str(subject))\n",
    "    \n",
    "    # initialize sequential neural network\n",
    "    model = Sequential()\n",
    "    # add a long short term memory layer specifying the input shape (length of 500 (segmented) with 3 axes)\n",
    "    model.add(LSTM(50, input_shape = (500, 3)))\n",
    "    # add a dense layer with a sigmoid activation function\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    # compile the neural network with a mae loss function and adam optimizer\n",
    "    model.compile(loss = 'mae', optimizer = 'adam')\n",
    "    try:\n",
    "        # fit the model using the training set and validate on the subject data left out\n",
    "        history = model.fit(trainData, trainLab, epochs = 10, batch_size = int(len(trainInd) / 20), \n",
    "                            validation_data = (testData, testLab))\n",
    "    # keyboard interrupt exception to plot all data acquried to this point (see plot to this point)\n",
    "    except(KeyboardInterrupt):\n",
    "        break\n",
    "    # prediction label is prediction on test data of fit neural network\n",
    "    PL = model.predict(testData)\n",
    "    # true labels are clinician scores from metadata\n",
    "    TL = testLab\n",
    "    # ROC curve will spit an error if not positive values are present\n",
    "    if all(TL == 0):\n",
    "        continue\n",
    "    # generate and plot ROC curve of each validation subject\n",
    "    fpr, tpr, thresholds = sklearn.metrics.roc_curve(TL, PL)\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.xlabel('False Positive Rate', fontsize = 12)\n",
    "    plt.ylabel('True Positive Rate', fontsize = 12)\n",
    "    plt.title('Receiver Operating Characteristic Curve', fontsize = 15)\n",
    "    \n",
    "#     plt.figure(figsize = (8, 8))\n",
    "#     plt.plot(history.history['loss'], label = 'Train')\n",
    "#     plt.plot(history.history['val_loss'], label = 'Test')\n",
    "#     plt.title(str(subject))\n",
    "#     plt.legend()\n",
    "#     plt.ylim((0,1))\n",
    "#     plt.show()\n",
    "plt.legend(valsubs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
