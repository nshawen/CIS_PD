{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "import pickle\n",
    "from scipy.stats import skew, kurtosis, pearsonr\n",
    "from scipy.signal import butter, welch, filtfilt, resample\n",
    "import copy\n",
    "import time\n",
    "import datetime\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "from PreprocessFcns import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set path to folder containing Subject Records\n",
    "path = r'//FS2.smpp.local\\\\RTO\\\\CIS-PD Study\\MJFF Curation\\Finalized Dataset'\n",
    "# Set path to Destination Folder\n",
    "dest = r'//FS2.smpp.local\\\\RTO\\\\CIS-PD Study\\Patient Record Correlation'\n",
    "#---------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Medication Reports\n",
    "table_med = 'Table10.csv'\n",
    "dest_ext_med = 'Medication Reports'\n",
    "file_name_med = 'med_timepoints.csv'\n",
    "\n",
    "# Symptom Reports\n",
    "table_symt = 'Table11.csv'\n",
    "dest_ext_symt = 'Symptom Reports'\n",
    "file_name_symt = 'symt_timepoints.csv'\n",
    "\n",
    "# Diaries\n",
    "table_diar = 'Table12.csv'\n",
    "dest_ext_diar = 'Diaries'\n",
    "file_name_diar = 'diar_timepoints.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Consolidated DataFrames\n",
    "timepoints_med = pd.read_csv(os.path.join(dest, dest_ext_med, file_name_med))\n",
    "timepoints_symt = pd.read_csv(os.path.join(dest, dest_ext_symt, file_name_symt))\n",
    "timepoints_diar = pd.read_csv(os.path.join(dest, dest_ext_diar, file_name_diar))\n",
    "\n",
    "# Group Record Types to Go Over All at Once\n",
    "records = [timepoints_med, timepoints_symt, timepoints_diar]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '//FS2.smpp.local\\\\\\\\RTO\\\\\\\\CIS-PD Study\\\\Patient Record Correlation\\\\Medication Reports\\\\1004 2017-06-21 181225.000.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-1c3fe9368a9d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     45\u001b[0m                                                 \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimepoints\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mentry\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Timestamp'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m13\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m                                                 \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimepoints\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mentry\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Timestamp'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m14\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m                                                 str(timepoints.loc[entry, 'Timestamp'])[17:] + '.csv'), index = False)\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, tupleize_cols, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[0;32m   3018\u001b[0m                                  \u001b[0mdoublequote\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3019\u001b[0m                                  escapechar=escapechar, decimal=decimal)\n\u001b[1;32m-> 3020\u001b[1;33m         \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3021\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3022\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    155\u001b[0m             f, handles = _get_handle(self.path_or_buf, self.mode,\n\u001b[0;32m    156\u001b[0m                                      \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 157\u001b[1;33m                                      compression=self.compression)\n\u001b[0m\u001b[0;32m    158\u001b[0m             \u001b[0mclose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[0;32m    422\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m             \u001b[1;31m# Python 3 and encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 424\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    425\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m             \u001b[1;31m# Python 3 and no explicit encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '//FS2.smpp.local\\\\\\\\RTO\\\\\\\\CIS-PD Study\\\\Patient Record Correlation\\\\Medication Reports\\\\1004 2017-06-21 181225.000.csv'"
     ]
    }
   ],
   "source": [
    "for timepoints in records:\n",
    "    \n",
    "    # Designate Medication Record Type due to Differing Relevant Data Time Range\n",
    "    # len(timepoints_med) = 24742\n",
    "    if len(timepoints) > 20000 and len(timepoints) < 30000:\n",
    "        \n",
    "        # Set Destination Folder\n",
    "        dest_ext = dest_ext_med\n",
    "        \n",
    "        for entry in range(len(timepoints)):\n",
    "\n",
    "            # Designate Watch Acceleration File According to Subject and Month of Record Entry\n",
    "            watch_filename = ('Table8_' + str(timepoints.loc[entry, 'SubjID']) + '_' + \n",
    "                              str(timepoints.loc[entry, 'Timestamp'])[:7] + '.csv')\n",
    "            # Read Watch Acc File in Chunks\n",
    "            watch_month_chunk = pd.read_csv(os.path.join(path, 'Table8', watch_filename), chunksize = 100000)\n",
    "\n",
    "            # Initiate Empty DataFrame for Watch Data Near Patient Record\n",
    "            watch_timepoint = pd.DataFrame(columns = ['SubjID', 'Timestamp', 'X', 'Y', 'Z'])\n",
    "\n",
    "            # Sequential Indices\n",
    "            i = 0\n",
    "            # Changing Index of Chunk\n",
    "            c = 0\n",
    "\n",
    "            # Look at One Chunk at a Time\n",
    "            for chunk in watch_month_chunk:\n",
    "\n",
    "                for acc in range(len(chunk)):\n",
    "\n",
    "                    # Add Acc Data Point to New DataFrame if Taken within Time Frame of Patient Record Entry\n",
    "                    if (pd.Timestamp(chunk.loc[c+acc, 'Timestamp']) >= \n",
    "                        pd.Timestamp(timepoints.loc[entry, 'Timestamp']) + pd.Timedelta('-30 min') and \n",
    "                        pd.Timestamp(chunk.loc[c+acc, 'Timestamp']) <= pd.Timestamp(timepoints.loc[entry, 'Timestamp']) + \n",
    "                        pd.Timedelta('30 min')):\n",
    "                        \n",
    "                        watch_timepoint.loc[i] = [chunk.loc[c+acc, 'SubjID'], pd.Timestamp(chunk.loc[c+acc, 'Timestamp']), \n",
    "                                                  chunk.loc[c+acc, 'X'], chunk.loc[c+acc, 'Y'], chunk.loc[c+acc, 'Z']]\n",
    "                        i += 1\n",
    "\n",
    "                c += 100000\n",
    "\n",
    "            # Save Each Compiled DataFrame of Acc Data Corresponding to a Patient Record Entry\n",
    "            watch_timepoint.to_csv(os.path.join(dest, dest_ext, str(timepoints.loc[entry, 'SubjID']) + ' ' + \n",
    "                                                str(timepoints.loc[entry, 'Timestamp'])[:13] + \n",
    "                                                str(timepoints.loc[entry, 'Timestamp'])[14:16] + \n",
    "                                                str(timepoints.loc[entry, 'Timestamp'])[17:] + '.csv'), index = False)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        # Choose Destination Folder Based on Record Type Processing\n",
    "        # len(timepoints_symt) = 4718\n",
    "        if len(timepoints) > 75280:\n",
    "            dest_ext = dest_ext_symt\n",
    "        # len(timepoints_diar) = 4718\n",
    "        if len(timepoints) < 30000:\n",
    "            dest_ext = dest_ext_diar\n",
    "\n",
    "        for entry in range(len(timepoints)):\n",
    "\n",
    "            # Designate Watch Acceleration File According to Subject and Month of Record Entry\n",
    "            watch_filename = ('Table8_' + str(timepoints.loc[entry, 'SubjID']) + '_' + \n",
    "                              str(timepoints.loc[entry, 'Timestamp'])[:7] + '.csv')\n",
    "            # Read Watch Acc File in Chunks\n",
    "            watch_month_chunk = pd.read_csv(os.path.join(path, 'Table8', watch_filename), chunksize = 100000)\n",
    "\n",
    "            # Initiate Empty DataFrame for Watch Data Near Patient Record\n",
    "            watch_timepoint = pd.DataFrame(columns = ['SubjID', 'Timestamp', 'X', 'Y', 'Z'])\n",
    "\n",
    "            # Sequential Indices\n",
    "            i = 0\n",
    "            # Changing Index of Chunk\n",
    "            c = 0\n",
    "\n",
    "            # Look at One Chunk at a Time\n",
    "            for chunk in watch_month_chunk:\n",
    "\n",
    "                for acc in range(len(chunk)):\n",
    "\n",
    "                    # Add Acc Data Point to New DataFrame if Taken within Time Frame of Patient Record Entry\n",
    "                    if (pd.Timestamp(chunk.loc[c+acc, 'Timestamp']) >= \n",
    "                        pd.Timestamp(timepoints.loc[entry, 'Timestamp']) + pd.Timedelta('-30 min') and \n",
    "                        pd.Timestamp(chunk.loc[c+acc, 'Timestamp']) <= pd.Timestamp(timepoints.loc[entry, 'Timestamp'])): \n",
    "                        \n",
    "                        watch_timepoint.loc[i] = [chunk.loc[c+acc, 'SubjID'], pd.Timestamp(chunk.loc[c+acc, 'Timestamp']), \n",
    "                                                  chunk.loc[c+acc, 'X'], chunk.loc[c+acc, 'Y'], chunk.loc[c+acc, 'Z']]\n",
    "                        i += 1\n",
    "\n",
    "                c += 100000\n",
    "\n",
    "            # Save Each Compiled DataFrame of Acc Data Corresponding to a Patient Record Entry\n",
    "            watch_timepoint.to_csv(os.path.join(dest, dest_ext, str(timepoints.loc[entry, 'SubjID']) + ' ' + \n",
    "                                                str(timepoints.loc[entry, 'Timestamp'])[:13] + \n",
    "                                                str(timepoints.loc[entry, 'Timestamp'])[14:16] + \n",
    "                                                str(timepoints.loc[entry, 'Timestamp'])[17:] + '.csv'), index = False)\n",
    "\n",
    "\n",
    "\n",
    "## Add 'If Statement' to find exceptions when ranges carry across months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24742\n",
      "75280\n",
      "4718\n"
     ]
    }
   ],
   "source": [
    "### TEST CELL\n",
    "\n",
    "# Print the Lengths of the Condensed Record Timepoints for Discerning Between Record Types Analyzed in Above Cell\n",
    "print(len(timepoints_med))\n",
    "print(len(timepoints_symt))\n",
    "print(len(timepoints_diar))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
